---
layout: post
title: Arima Introduction
categories: Statistics
tags:
- timeseries
- statistics
---

A linear regression equation has the following form

$$ Y = b{_0} + b{_1}X{_1} + b{_2}X{_2} + b{_3}X{_3} +....+ b{_p}X{_p} + e $$ -- **(1)**

where Y is the forecast variable, $$ X{_1} $$ through $$ X{_p} $$ are the explanatory variables , $$ b{_0} $$ through $$ b{_p} $$ are the linear regression coefficients and $$ e $$ is the error term.

Now consider the following equation

$$ Y{_t} = b{_0} + b{_1}Y{_{t-1}} + b{_2}Y{_{t-2}} + b{_3}Y{_{t-3}} +....+ b{_p}Y{_{t-p}}+ e{_t} $$ -- **(2)**

The equation differs from the first one in the variables being  **time lagged** variables of the forecast variable , hence the term **autoregression (AR)**  is used to describe the equation**(2)**.   

A time series model can also be constructed which uses **past errors** as the explanatory variables   

$$ Y{_t} = b{_0} + b{_1}e{_{t-1}} + b{_2}e{_{t-2}} + b{_3}e{_{t-3}} +....+ b{_p}e{_{t-p}}+ e{_t} $$ -- **(3)**

Equation **(3)** is set up among successive error terms and this equation is known as the **moving average (MA)** model. Autorgressive(AR) models can be effectively coupled with moving average models to form a general and useful class of time series models called autoregressive moving average **(ARMA)** models. However they can only be used when the data is **STATIONARY**. This class of models can be extended to non stationary data by diffrencing of the data series. These are called **auto regressive integrated moving average (ARIMA)** models.

**Source** : FORECASTING METHODS AND APPLICATIONS.Book by Rob J. Hyndman, Spyros Makridakis, and Steven C. Wheelwright
