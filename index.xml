<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Thoughts - Ambarish</title>
    <link>/</link>
    <description>Recent content on Thoughts - Ambarish</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>© Copyright notice</copyright>
    <lastBuildDate>Fri, 10 Sep 2021 10:00:00 +0030</lastBuildDate><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Binomial Distributions</title>
      <link>/posts/binomial-distributions/</link>
      <pubDate>Fri, 10 Sep 2021 10:00:00 +0030</pubDate>
      
      <guid>/posts/binomial-distributions/</guid>
      <description>Binomial Probability distribution has the following characteristics:
  A fixed number of trials n. e.g., 20 coin toss , 40 students
  A binary outcome, a success and a failure. Probability of success is p, probability of failure is 1-p. e.g., head or tail in a coin toss , pass or fail of sttudents in an exam, positive and negative results of a test of a patient.
  Constant probability for each trial.</description>
    </item>
    
    <item>
      <title>Probability Distributions</title>
      <link>/posts/probability-distributions/</link>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/probability-distributions/</guid>
      <description>Probability distribution is also known as Probability function.
 This gives the probabilities of all possible outcomes A mathematical function which maps each possible outcome x to the probability p(x) The probabilities must all sum or integrate to 1  Discrete and Continous Probability distribution Discrete probability functions can take only discrete values. Examples include Dead/ Alive , numbers obtained by rolling a die, treatment / placebo, whole numbers
Continuous probability functions can take any value within a range.</description>
    </item>
    
    <item>
      <title>Recommendation series in Microsoft Reactor</title>
      <link>/posts/reactor-recommendation-series/</link>
      <pubDate>Mon, 21 Jun 2021 01:00:00 +0030</pubDate>
      
      <guid>/posts/reactor-recommendation-series/</guid>
      <description>We will adopt a case study approach in understanding the concepts and build a recommendation engine from scratch using TF-IDF , cosine similarity, word embeddings and deploy it in Azure ML. The series will span 5 Fridays 5PM - 6PM IST time zone.
  Introduction to Azure ML - Friday, June 25, 2021 
  Recommendation engine using Text data ,Cosine Similarity and TFIDF technique -Friday, July 2, 2021</description>
    </item>
    
    <item>
      <title>Roadmap of the Recommendation series Reading</title>
      <link>/posts/roadmap-recommendation-series/</link>
      <pubDate>Tue, 18 May 2021 01:00:00 +0030</pubDate>
      
      <guid>/posts/roadmap-recommendation-series/</guid>
      <description>A roadmap of reading the Recommendation series involving TF-IDF , Cosine Similarity , Word Embeddings and deploying into AzureML
  Recommendation engine using Text data ,Cosine Similarity and TFIDF technique
  Recommendation engine using Text data ,Cosine Similarity and TFIDF technique , Azure ML
  Word Embeddings
  Recommendation engine using Text data ,Cosine Similarity and word embeddings technique
  Recommendation engine using Text data ,Cosine Similarity and word embeddings technique, , Azure ML</description>
    </item>
    
    <item>
      <title>Word embeddings</title>
      <link>/posts/word-embeddings/</link>
      <pubDate>Tue, 18 May 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/word-embeddings/</guid>
      <description>From the TensorFlow documentation word embeddings documentation
 Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding.
  Importantly, you do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify).
  Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer).</description>
    </item>
    
    <item>
      <title>Recommendation engine using Text data ,Cosine Similarity and Word Embeddings , Azure ML</title>
      <link>/posts/recommender-career-spacy-azure/</link>
      <pubDate>Sat, 15 May 2021 01:00:00 +0030</pubDate>
      
      <guid>/posts/recommender-career-spacy-azure/</guid>
      <description>What are we trying to do We will build a very simple recommendation engine using Text Data. To demostrate this we would use a case study approach and build a recommendation engine for a non profit organization Career Village. I have detailed post on the methodology of the recommendation engine in the post here. In this post we will show of how we train, infer and deploy the solution in Azure.</description>
    </item>
    
    <item>
      <title>Recommendation engine using Text data ,Cosine Similarity and word embeddings technique</title>
      <link>/posts/recommender-career-spacy/</link>
      <pubDate>Sat, 15 May 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/recommender-career-spacy/</guid>
      <description>What are we trying to do We will build a very simple recommendation engine using Text Data. To demostrate this we would use a case study approach and build a recommendation engine for a non profit organization Career Village.
CareerVillage.org is a nonprofit that crowdsources career advice for underserved youth. Founded in 2011 in four classrooms in New York City, the platform has now served career advice from 25,000 volunteer professionals to over 3.</description>
    </item>
    
    <item>
      <title>Recommendation engine using Text data ,Cosine Similarity and TFIDF technique , Azure ML</title>
      <link>/posts/recommender-career-tfidf-azure/</link>
      <pubDate>Fri, 14 May 2021 01:00:00 +0030</pubDate>
      
      <guid>/posts/recommender-career-tfidf-azure/</guid>
      <description>What are we trying to do We will build a very simple recommendation engine using Text Data. To demostrate this we would use a case study approach and build a recommendation engine for a non profit organization Career Village. I have detailed post on the methodology of the recommendation engine in the post here. In this post we will show of how we train, infer and deploy the solution in Azure.</description>
    </item>
    
    <item>
      <title>Recommendation engine using Text data ,Cosine Similarity and TFIDF technique</title>
      <link>/posts/recommender-career-tfidf/</link>
      <pubDate>Thu, 13 May 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/recommender-career-tfidf/</guid>
      <description>What are we trying to do We will build a very simple recommendation engine using Text Data. To demostrate this we would use a case study approach and build a recommendation engine for a non profit organization Career Village.
CareerVillage.org is a nonprofit that crowdsources career advice for underserved youth. Founded in 2011 in four classrooms in New York City, the platform has now served career advice from 25,000 volunteer professionals to over 3.</description>
    </item>
    
    <item>
      <title>Latex  Cheatsheet</title>
      <link>/posts/matrix-helper/</link>
      <pubDate>Tue, 04 May 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/matrix-helper/</guid>
      <description>Plain Matrix $ \\begin{matrix} 1 &amp;amp; 2 &amp;amp; 3\\\\ a &amp;amp; b &amp;amp; c \\end{matrix} $ $ \begin{matrix} 1 &amp;amp; 2 &amp;amp; 3\\
a &amp;amp; b &amp;amp; c \end{matrix} $
Square Bracket Matrix $ \\begin{bmatrix} 1 &amp;amp; 2 &amp;amp; 3\\\\ a &amp;amp; b &amp;amp; c \\end{bmatrix} $ $ \begin{bmatrix} 1 &amp;amp; 2 &amp;amp; 3\\
a &amp;amp; b &amp;amp; c \end{bmatrix} $
Parentheses;round brackets Matrix $ \\begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3\\\\ a &amp;amp; b &amp;amp; c \\end{pmatrix} $ $ \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3\\</description>
    </item>
    
    <item>
      <title>Convolutions in 1 dimension</title>
      <link>/posts/conv1d-pytorch/</link>
      <pubDate>Mon, 26 Apr 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/conv1d-pytorch/</guid>
      <description>Basics The Convolutional block is one of the basic building blocks used in deep learning. We go in-depth with Convolution in 1 dimension and understand the basics of convolution, strides, and padding. We explain visually and also through PyTorch code to verify our concepts.
The Kernel takes an Input and provides an output which is sometimes referred to as a feature map
The Kernel is made up of many things .</description>
    </item>
    
    <item>
      <title>Red Wine Quality prediction using AzureML, AKS with TensorFlow Keras</title>
      <link>/posts/red-wine-quality-azureml-keras/</link>
      <pubDate>Sat, 24 Apr 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/red-wine-quality-azureml-keras/</guid>
      <description>What are we trying to do Predict the Quality of Red Wine using Tensorflow Keras deep learning framework given certain attributes such as fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates, and alcohol
We divide our approach into 2 major blocks:
 Building the Model in Azure ML Inference from the Model in Azure ML  Building the model in Azure ML has the following steps:</description>
    </item>
    
    <item>
      <title>AdaptiveAvgPool2d in PyTorch</title>
      <link>/posts/adaptiveavgpool2d-pytorch/</link>
      <pubDate>Sun, 18 Apr 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/adaptiveavgpool2d-pytorch/</guid>
      <description>I had trouble understanding the AdaptiveAvgPool2d function in PyTorch. The following examples helped me to teach myself better. Hopefully, somebody may benefit from this.
Example 1 import torch import torch.nn as nn import numpy as np m = nn.AdaptiveAvgPool2d((1)) x = np.array( [ [ 2. , 3.], [ 4. , 1.], ]) input = torch.tensor(x) print(input) output = m(input) print(output) print(torch.mean(input)) The output will be equal to torch.mean(input)
Example 2 with a 3 x 3 x 3 tensor x = np.</description>
    </item>
    
    <item>
      <title>Bees Health detection using Azure Custom Vision Service</title>
      <link>/posts/bees-health-detection-azure-cognitive-services/</link>
      <pubDate>Wed, 31 Mar 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/bees-health-detection-azure-cognitive-services/</guid>
      <description>Every third bite of food relies on pollination by bees. Honey beehive losses are quite prevalent due to the diseased bees.
While many indications of hive strength and health are visible on the inside of the hive, frequent check-ups on the hive are time-consuming and disruptive to the bees&#39; workflow and hive in general. By investigating the bees that leave the hive, we can gain a more complete understanding of the hive itself.</description>
    </item>
    
    <item>
      <title>Cross Entropy Loss</title>
      <link>/posts/2021-03-27-cross-entropy-loss/</link>
      <pubDate>Sat, 27 Mar 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/2021-03-27-cross-entropy-loss/</guid>
      <description>Cross Entropy Loss In a supervised learning problem for predicting classes, we predict probabilities for the classes. To determine how successful we are predicting the classes, we require a loss function.
Cross-Entropy loss function provides a loss function to calculate the loss between the actual classes and the predicted probabilities
This can be represented as
 Get the predicted probability of the class Get the actual label of the class ( 1 or 0 ) Multiply the actual label with the log of the predicted probability of the class Sum the values obtained from each of the classes Multiply by -1 the value obtained in Step 4  This is the loss for a single observation.</description>
    </item>
    
    <item>
      <title>Azure ML DataStores and Datasets</title>
      <link>/posts/2021-03-15-azure-ml-datastores-datasets-basics/</link>
      <pubDate>Mon, 15 Mar 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/2021-03-15-azure-ml-datastores-datasets-basics/</guid>
      <description>DataStores
In Azure ML, datastores are references to storage locations, such as Azure Storage blob containers. Every workspace has a default datastore - usually the Azure storage blob container that was created with the workspace.
When data is uploaded into the datastore through the following code
default_ds.upload_files(files=[&amp;#39;data/diabetes.csv&amp;#39;, &amp;#39;data/diabetes2.csv&amp;#39;], # Upload the diabetes csv files in /data target_path=&amp;#39;diabetes-data/&amp;#39;, # Put it in a folder path in the datastore overwrite=True, # Replace existing files of the same name show_progress=True) we can see the files in the Azure Storage Account &amp;gt; Containers &amp;gt; Blob Stores</description>
    </item>
    
    <item>
      <title>Azure ML Experiments and Runs basics</title>
      <link>/posts/2021-03-13-azure-ml-experiments-runs-basics/</link>
      <pubDate>Sat, 13 Mar 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/2021-03-13-azure-ml-experiments-runs-basics/</guid>
      <description>An experiment is a grouping of many runs from a specified script. It always belongs to a workspace. When we submit a run, we provide an experiment name. Information for the run is stored under that experiment. If the name doesn&amp;rsquo;t exist when we submit an experiment, a new experiment is automatically created.
  A run is a single execution of a training script. An experiment will typically contain multiple runs.</description>
    </item>
    
    <item>
      <title>2 Stories, Azure ML, Azure Kubernetes Service, Model deployment</title>
      <link>/posts/2021-03-11-two-stories-azureml-aks/</link>
      <pubDate>Thu, 11 Mar 2021 00:00:00 +0030</pubDate>
      
      <guid>/posts/2021-03-11-two-stories-azureml-aks/</guid>
      <description>Let&amp;rsquo;s start with 2 of my experiences with machine learning in data science competitions and writing a research paper. This will give us enough motivation to understand why platforms such as AzureML are required.
Story 1 - A data science competition  I participated in a data science competition that required predicting time series data. For this, I tried 5 different algorithms Arima, ETS, Facebook Prophet, XGBoost, and Random Forest. I also used several imputation techniques which also involved a number of hyperparameters.</description>
    </item>
    
    <item>
      <title>Azure ML HyperParameters</title>
      <link>/posts/2020-11-08-azure-hyperparameters-basics/</link>
      <pubDate>Sun, 08 Nov 2020 00:00:00 +0030</pubDate>
      
      <guid>/posts/2020-11-08-azure-hyperparameters-basics/</guid>
      <description>Parameter
A variable of a model that the machine learning system trains on its own. For example, weights are parameters whose values the machine learning system gradually learns through successive training iterations.
Hyperparameter
The &amp;ldquo;knobs&amp;rdquo; that we tweak during successive runs of training a model. For example, learning rate is a hyperparameter.
Hyperparameters have the following properties
  Search space - The set of hyperparameter values tried during hyperparameter tuning is known as the search space.</description>
    </item>
    
    <item>
      <title>Azure ML Environments</title>
      <link>/posts/2020-11-04-azure-ml-environments-runconfigs-basics/</link>
      <pubDate>Wed, 04 Nov 2020 00:00:00 +0030</pubDate>
      
      <guid>/posts/2020-11-04-azure-ml-environments-runconfigs-basics/</guid>
      <description>An environment is the encapsulation of the environment where training or scoring of the machine learning model happens. The environment specifies
 the Python packages, environment variables, and software settings around your training and scoring scripts.  Environments are of three types curated, user-managed, and system-managed.
Curated environments are provided by Azure Machine Learning and are available in the workspace by default.
In user-managed environments, the person is responsible for setting up the environment and installing every package that the training script needs on the compute target.</description>
    </item>
    
    <item>
      <title>Azure ML workspace basics</title>
      <link>/posts/2020-11-01-azure-ml-workspace-basics/</link>
      <pubDate>Sun, 01 Nov 2020 00:00:00 +0030</pubDate>
      
      <guid>/posts/2020-11-01-azure-ml-workspace-basics/</guid>
      <description>Azure ML has a top level component which is the Workspace. The workspace contains all the components of the Azure Machine Learning space.
The workspace is associated with
 Azure subscription Azure Key Vault Azure Application Insights  It is associated with the following assets
 Datasets Experiments Pipelines Models EndPoints  The workspace manages the following
 Datastores Compute  The workspace can be used for authoring
 Notebooks Automated ML Designer  You can implement via code</description>
    </item>
    
    <item>
      <title>Tensorflow basics</title>
      <link>/posts/2020-10-07-tensorflow-basics/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0030</pubDate>
      
      <guid>/posts/2020-10-07-tensorflow-basics/</guid>
      <description>Sequential API
Validation Regularization Callback
Saving Models</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Fri, 19 Apr 2019 21:37:58 +0530</pubDate>
      
      <guid>/about/</guid>
      <description>I am a Business and Technology Consultant for more than 20 Years. I am a data lover and compete regularly in data science competitions. I had won Eight Data Science Competition Awards ( 1 sponsored by NASA, Seven sponsored by Kaggle - A Google Company).
NASA has recognized me as a Citizen Scientist and has been extremely generous to have a page here</description>
    </item>
    
    <item>
      <title>Donors Choose Recommendation Project ( Two Awards )</title>
      <link>/awards/2018-05-30-donors-choose-recommendation-project/</link>
      <pubDate>Wed, 30 May 2018 02:01:58 +0530</pubDate>
      
      <guid>/awards/2018-05-30-donors-choose-recommendation-project/</guid>
      <description>Founded in 2000 by a Bronx history teacher, DonorsChoose.org has raised $685 million for America&amp;rsquo;s classrooms. Teachers at three-quarters of all the public schools in the U.S. have come to DonorsChoose.org to request what their students need, making DonorsChoose.org the leading platform for supporting public education.
To date, 3 million people and partners have funded 1.1 million DonorsChoose.org projects. But teachers still spend more than a billion dollars of their own money on classroom materials.</description>
    </item>
    
    <item>
      <title>Donors Choose Application Screening Kernel Award</title>
      <link>/awards/2018-04-25-donors-choose-application-screening/</link>
      <pubDate>Wed, 25 Apr 2018 02:01:58 +0530</pubDate>
      
      <guid>/awards/2018-04-25-donors-choose-application-screening/</guid>
      <description>Founded in 2000 by a high school teacher in the Bronx, DonorsChoose.org empowers public school teachers from across the country to request much-needed materials and experiences for their students. At any given time, there are thousands of classroom requests that can be brought to life with a gift of any amount.
DonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it&amp;rsquo;s approved to be posted on the DonorsChoose.</description>
    </item>
    
    <item>
      <title>Kiva Kernel Award</title>
      <link>/awards/2018-04-04-kiva-kernels-award/</link>
      <pubDate>Wed, 04 Apr 2018 02:01:58 +0530</pubDate>
      
      <guid>/awards/2018-04-04-kiva-kernels-award/</guid>
      <description>Kiva.org is an online crowdfunding platform to extend financial services to poor and financially excluded people around the world. Kiva lenders have provided over $1 billion dollars in loans to over 2 million people. In order to set investment priorities, help inform lenders, and understand their target communities, knowing the level of poverty of each borrower is critical. However, this requires inference based on a limited set of information for each borrower.</description>
    </item>
    
    <item>
      <title>Random walk with Penguins</title>
      <link>/posts/2018-01-01-random-walk-with-penguins/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0030</pubDate>
      
      <guid>/posts/2018-01-01-random-walk-with-penguins/</guid>
      <description>Honoured to win the 1st prize in a Data Science competition Random Walk of Penguins hosted by DrivenData. Sharing the winning approach here.
Introduction Penguins are among the most charismatic animals in the world and have captured the imaginations of news-makers, scientists, film producers, and the general public. Beyond their general intrinsic value, they are considered important ecosystem indicators. In other words, monitoring these beautiful species can tell us a lot about the general health of the Antarctic because penguins are important krill and fish predators, and changes (natural or anthropogenic) that influence prey abundance and environmental conditions will ultimately be detected through changes in distribution or population size.</description>
    </item>
    
    <item>
      <title>Themed Kernel Award Winner - Spooky EDA</title>
      <link>/awards/2017-12-25-spooky-eda/</link>
      <pubDate>Mon, 25 Dec 2017 02:01:58 +0530</pubDate>
      
      <guid>/awards/2017-12-25-spooky-eda/</guid>
      <description>Kaggle organized a Halloween playground competition, in which Text Miners were challenged to predict the author of excerpts from horror stories by Edgar Allan Poe, Mary Shelley, and HP Lovecraft.
Prizes were given for most upvoted kernels, most upvoted discussions and themed kernels such as Python Tutorial, R Tutorial, Creative Feature Engineering and Creative Data Visualization. Honoured to receive the R Tutorial prize for the kernel Tutorial:Detailed Spooky Fun EDA and Modelling</description>
    </item>
    
    <item>
      <title>Chicago Restaurants Inspections Text Mining</title>
      <link>/posts/2017-10-19-chicago-restaurants-inspections/</link>
      <pubDate>Thu, 19 Oct 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-10-19-chicago-restaurants-inspections/</guid>
      <description>Restaurant inspections ensure that food served to the public at licensed food establishments follows food safety guidelines. The Food Protection Division of the Chicago Department of Public Health (CDPH) is committed to maintaining the safety of food bought, sold, or prepared for public consumption in Chicago by carrying out science-based inspections of all retail food establishments. These inspections promote public health in areas of food safety and sanitation and prevent the occurrence of food-borne illness.</description>
    </item>
    
    <item>
      <title>African Conflicts</title>
      <link>/posts/2017-10-17-african-conflicts/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-10-17-african-conflicts/</guid>
      <description>We examine a dataset from ACLED(Armed Conflict Location and Event Project).The Armed Conflict Location and Event Data Project is designed for disaggregated conflict analysis and crisis mapping. This dataset codes the dates and locations of all reported political violence and protest events in dozens of developing countries in Africa. Political violence and protest includes events that occur within civil wars and periods of instability, public protest and regime breakdown. The project covers all African countries from 1997 to the present.</description>
    </item>
    
    <item>
      <title>Austin Bike Share EDA with Maps and TimeSeries</title>
      <link>/posts/2017-10-07-austin-bikeshare/</link>
      <pubDate>Sat, 07 Oct 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-10-07-austin-bikeshare/</guid>
      <description>Catching a show on Red River? Eating on the East Side? Paddleboarding at Zilker? All of the above?
Hop on a B-cycle and coast your way through the People’s Republic of Austin
We explore the Austin Bike Share data for the following topics :
 Top 10 Common Start Stations Top 10 Common Destination Stations Get Top 10 Most Popular Routes Map of Bike Stations Month , Day , Time Analysis Types of Subscriber Month , Day , Time Analysis for Local365 Duration of Trips Trips for Station ID #2575 BikeTrips for Station ID #2575 (Week wise) SXSW 2017 SXSW 2016  A detailed report Austin Bike Share Analysis has the complete Data Visualization with Maps.</description>
    </item>
    
    <item>
      <title>Fun in TextMining with Simpsons</title>
      <link>/posts/2017-10-07-fun-in-textmining-with-simpsons/</link>
      <pubDate>Sat, 07 Oct 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-10-07-fun-in-textmining-with-simpsons/</guid>
      <description>This dataset contains the characters, locations, episode details, and script lines for approximately 600 Simpsons episodes, dating back to 1989.
I had fun learning Text Mining with Simpsons.Hope you will also enjoy the same while I had writing the text mining and data visualization code.
A detailed report Fun in Text Mining with Simpsons has the complete Data Visualization with Text Mining and Modelling.</description>
    </item>
    
    <item>
      <title>Meteorite Landings</title>
      <link>/posts/2017-10-05-meteorite-landings/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-10-05-meteorite-landings/</guid>
      <description>We examine a dataset from NASA Meteorite Landings and do a complete Exploratory Data Analysis.
The Meteoritical Society collects data on meteorites that have fallen to Earth from outer space. This dataset includes the location, mass, composition, and fall year for over 45,000 meteorites that have struck our planet.
A detailed report Fun with Meteorite Landings has the complete Exploratory Data Analysis.
A book on this report can be found in Little Book on Exploratory Data Analysis.</description>
    </item>
    
    <item>
      <title>Crime in Los Angeles</title>
      <link>/posts/2017-09-25-la-crime/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-09-25-la-crime/</guid>
      <description>We investigate the Crime in LA. We do Exploratory Data analysis on various topics such as the Month of Crime ,Day of Crime,Time of Crime. We also explore how the Crimes are related to the Sex and Age of the Victims, Crime Types, Crime Types of persons aged 70 and above. We explore on the Crimes at different Premises,Types of Crimes at different Premises,victim Descent Analysis and an analysis of Weapons used in Crime.</description>
    </item>
    
    <item>
      <title>Weekly Kaggle Kernel Award Winner - African Conflicts</title>
      <link>/awards/2017-08-18-weekly-kernel-winner-african-conflicts-copy/</link>
      <pubDate>Fri, 18 Aug 2017 02:01:58 +0530</pubDate>
      
      <guid>/awards/2017-08-18-weekly-kernel-winner-african-conflicts-copy/</guid>
      <description>We examine a dataset from ACLED(Armed Conflict Location and Event Project).The Armed Conflict Location and Event Data Project is designed for disaggregated conflict analysis and crisis mapping. This dataset codes the dates and locations of all reported political violence and protest events in dozens of developing countries in Africa. Political violence and protest includes events that occur within civil wars and periods of instability, public protest and regime breakdown. The project covers all African countries from 1997 to the present.</description>
    </item>
    
    <item>
      <title>Random walk with Penguins</title>
      <link>/awards/2017-07-27-random-walk-with-penguins/</link>
      <pubDate>Thu, 27 Jul 2017 02:01:58 +0530</pubDate>
      
      <guid>/awards/2017-07-27-random-walk-with-penguins/</guid>
      <description>Honoured to win the 1st prize in a Data Science competition Random Walk of Penguins hosted by DrivenData. Sharing the winning approach here.
Introduction Penguins are among the most charismatic animals in the world and have captured the imaginations of news-makers, scientists, film producers, and the general public. Beyond their general intrinsic value, they are considered important ecosystem indicators. In other words, monitoring these beautiful species can tell us a lot about the general health of the Antarctic because penguins are important krill and fish predators, and changes (natural or anthropogenic) that influence prey abundance and environmental conditions will ultimately be detected through changes in distribution or population size.</description>
    </item>
    
    <item>
      <title>activation functions</title>
      <link>/posts/2017-07-06-activation-functions/</link>
      <pubDate>Thu, 06 Jul 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-07-06-activation-functions/</guid>
      <description>Sigmoid function takes values between 0 and 1
$ {sigmoid} = \frac {e^x} {( 1+ e^x )} $
This is used in logistic regression.
The sigmoid graph is generated by the R code provided below.
Softmax function is used to calculate the probablities in multiple classes. Suppose we have a image of a digit. We want to calculate whether it is a 1, 2, 3, and so on. Softmax would provide the probablity for each of the classes.</description>
    </item>
    
    <item>
      <title>Installing XGBoost on Anaconda on Windows</title>
      <link>/posts/2017-07-06-installing-xgboost-anaconda-windows/</link>
      <pubDate>Thu, 06 Jul 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-07-06-installing-xgboost-anaconda-windows/</guid>
      <description>The installation instructions are exactly the same as in the Installing XGBoost For Anaconda on Windows except Step 10 since the name of the DLL created is libxgboost.dll but the Python Module expects the dll of the name xgboost.dll.
Step 1 : Install Anaconda
Step 2 : Install Git on Windows
Step 3 : Launch Git Bash window
Step 4 : The directory in which the code is to be installed in my case is D:\XGBoostCode</description>
    </item>
    
    <item>
      <title>California WireTapping</title>
      <link>/posts/2017-06-17-california-wiretapping/</link>
      <pubDate>Sat, 17 Jun 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-06-17-california-wiretapping/</guid>
      <description>In 2016, California investigators used state wiretapping laws 563 times to capture 7.8 million communications from 181,000 people, and only 19% of these communications were incriminating. The year&amp;rsquo;s wiretaps cost nearly $30 million.
We know this, and much more, now that the California Department of Justice (CADOJ) for the first time has released to EFF the dataset underlying its annual wiretap report to the state legislature.
The California WireTappinghas a detailed analysis of the same.</description>
    </item>
    
    <item>
      <title>Uttar Pradesh Assembly Elections 2017 Data Visualization</title>
      <link>/posts/2017-06-15-up-elections-2017/</link>
      <pubDate>Thu, 15 Jun 2017 00:00:00 +0030</pubDate>
      
      <guid>/posts/2017-06-15-up-elections-2017/</guid>
      <description>The assembly election results for Uttar Pradesh(UP) ,largest state in India were surprising to say the least. Never in the past has any single party secured a similar mandate. UP with a population of around 220 million is as big as the whole of United States. It has 403 constituencies each having its own demographic breakup. The election was conducted in 7 phases.
The Exploratory Analysis UP Elections 2017has a detailed analysis of the same.</description>
    </item>
    
    <item>
      <title>Adverse Food Events</title>
      <link>/posts/2017-10-07-adverse-food-events/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/2017-10-07-adverse-food-events/</guid>
      <description>The CFSAN Adverse Event Reporting System (CAERS) is a database that contains information on adverse event and product complaint reports submitted to FDA for foods, dietary supplements, and cosmetics. The database is designed to support CFSAN’s safety surveillance program.
We explore the data as outlined below :
 Ten Most Common Symptoms Ten Most Common Product Name Ten Most Common Industry Name Ages Commonly Affected Distribution of Ages Ten Most Common Outcomes Outcomes and Products associated with Adverse Events Symptoms and the Products Causing it Time Analysis of Adverse Events Products in Adverse Events for January Gender and Adverse Events  A detailed report Adverse Food Events EDA has the complete Data Visualization.</description>
    </item>
    
    <item>
      <title>Azure ML Pipelines</title>
      <link>/posts/2020-11-05-azure-pipelines-basics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/2020-11-05-azure-pipelines-basics/</guid>
      <description>Different types of pipelines are
In Azure Machine Learning, a pipeline is a workflow of machine learning tasks in which each task is implemented as a step.
 Steps can be arranged sequentially or in parallel Each step can be run on a specific compute target, making it possible to combine different types of processing as required to achieve an overall goal A pipeline can be executed as a process by running the pipeline as an experiment Each step in the pipeline runs on its allocated compute target as part of the overall experiment run.</description>
    </item>
    
    <item>
      <title>Intro to Deep Learning</title>
      <link>/courses/intro-to-deep-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/courses/intro-to-deep-learning/</guid>
      <description>This is the course page for the Course Intro to Deep Learning. Please also enroll in Kaggle Learn Intro to Deep Learning course to complete the exercises. Also watch the lectures where we have added our own explanations.
   Topic Description Video Link     01- single neuron This video introduces the concept of the simplest neural network, the single neuron Single Neuron   01-exercise single neuron This video explains step by step the exercise on the single neuron.</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning and Convolutional Neural Networks</title>
      <link>/testimonials/deeplearning-cnn-0/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/testimonials/deeplearning-cnn-0/</guid>
      <description>Approaches towards a session not just involve the topic matter, but also creating influence and motivating students to learn. I think you exactly did that. It was an absolute privilege to be able to attend your session. Thoroughly enjoyed your session. A bit of coding demonstration alongside theory was a great idea. It was an extensive 6.5 hrs long session with an hour break in between.</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning and Convolutional Neural Networks</title>
      <link>/testimonials/deeplearning-cnn-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/testimonials/deeplearning-cnn-1/</guid>
      <description>It was a pleasure attending your session at the short term course organised at Jadavpur University. Loved your teaching style of matching the deep learning concepts to the PyTorch codes.</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning and Convolutional Neural Networks</title>
      <link>/testimonials/deeplearning-cnn-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/testimonials/deeplearning-cnn-2/</guid>
      <description>Your course was very helpful and explained in quite lucid way which made possible for us to understand things. You explained in quite interesting way.It was nice doing this Deep Learning course with you.Thank you.</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning and Convolutional Neural Networks</title>
      <link>/testimonials/deeplearning-cnn-3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/testimonials/deeplearning-cnn-3/</guid>
      <description>Today&amp;rsquo;s session on deep learning was really so much interesting. Specially the description of several topics along with demos was really helpful for beginners in ML like me. Thank you so much Sir for this wonderful session and sharing such valuable information .</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning and Convolutional Neural Networks</title>
      <link>/testimonials/deeplearning-cnn-4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/testimonials/deeplearning-cnn-4/</guid>
      <description>It was really a very interesting session, especially the CNN. I was really eager about this topic but due to some reason or the other, I did not got the opportunity to gain the knowledge about this concept. I believe this will help me a lot in my coming thesis and future research works. Thanks a lot.</description>
    </item>
    
    <item>
      <title>Introduction to Deep Learning and Convolutional Neural Networks</title>
      <link>/testimonials/deeplearning-cnn-5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/testimonials/deeplearning-cnn-5/</guid>
      <description>It was a really good session. The technique of teaching the theory and practical parallelly was pretty amazing. Would love to attend another session of yours.</description>
    </item>
    
    <item>
      <title>Little Book on Data Visualization and Modelling</title>
      <link>/books/03-littlebookmodelling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/books/03-littlebookmodelling/</guid>
      <description>You can find the book here
This is a Little Book on Data Visualization,Maps and Time series Forecasts and Modelling on the Kaggle Dataset Crime in LA</description>
    </item>
    
    <item>
      <title>Little Book on Exploratory Data Analysis</title>
      <link>/books/02-littlebookeda/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/books/02-littlebookeda/</guid>
      <description>You can find the book here
This book provides a gentle and hands on introduction to Exploratory Data Analysis. If you are tired of reading through pages of text and would like to get your hands dirty and experience on how to do a quick and detailed exploratory data analysis, then you are in the right place. This book takes the following datasets and does a detailed EDA
 Womens Tennis matches dataset Meteorite Landings dataset from NASA Adverse Food Events dataset from FDA  </description>
    </item>
    
    <item>
      <title>Little Book on Text Mining</title>
      <link>/books/01-littlebooktextmining/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/books/01-littlebooktextmining/</guid>
      <description>This Little Book on Text Mining provides a gentle and hands on introduction to Text Mining. If you are tired of reading through pages of text and would like to get your hands dirty and experience on how to do a quick and detailed text mining, then you are in the right place. This book does a detailed Text Mining and Modelling on the following datasets
  Spooky Author Identification dataset from Kaggle</description>
    </item>
    
    <item>
      <title>Melbourne Housing Market Data Visualization</title>
      <link>/posts/2017-06-16-melb-housing-market/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/posts/2017-06-16-melb-housing-market/</guid>
      <description>Melbourne is currently experiencing a housing bubble (some experts say it may burst soon). Maybe someone can find a trend or give a prediction? Which suburbs are the best to buy in? Which ones are value for money? Where&amp;rsquo;s the expensive side of town? And more importantly where should your distant cousin :-) buy a 2 bedroom unit?
The Melbourne Housing Market has a detailed analysis of the same.The analysis provides insights into the following</description>
    </item>
    
  </channel>
</rss>
