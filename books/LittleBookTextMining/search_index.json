[
["index.html", "Little Book on Text Mining Chapter 1 Introduction 1.1 Spooky Author Identification Dataset", " Little Book on Text Mining Ambarish Ganguly Chapter 1 Introduction This Little Book on Text Mining provides a gentle and hands on introduction to Text Mining. If you are tired of reading through pages of text and would like to get your hands dirty and experience on how to do a quick and detailed text mining, then you are in the right place. This book does a detailed Text Mining and Modelling on the following datasets Spooky Author Identification dataset from Kaggle Yelp Data Reviews dataset from Kaggle The book focuses on Three main areas Exploratory Data Analysis , TF IDF concept and the application of it ,Bigrams ,Trigrams ,Relationship among various words ( Word Clouds and Bar Plots ) Detailed Sentiment Analysis and insights from it using different Sentiment Analysis lexicons such as AFINN , NRC Modelling using feature engineering and supervised learning techniques such as XGBoost and Multinomial Logistic Regression.Modelling using unsupervised learning techniques such as Topic Modelling. 1.1 Spooky Author Identification Dataset The Spooky Author Identification dataset from Kaggle has excerpts from horror stories by Edgar Allan Poe, Mary Shelley, and HP Lovecraft. The competition challenges to predict the author of excerpts. The dataset can be found in Kaggle. This chapter focuses on the following topics Word Length comparison among the various authors Common words used by the authors TF IDF concept and the application of it Bigrams Trigrams Relationship among various words Sentiment Analysis NRC Sentiment Analysis Building features using the Sentiment Score Building features using the NRC Sentiment Score Words Commonly used by Males and Females in Authors’ text Evaluation of the Document Term Matrix Topic Modelling Predictions using the XGBoost Model Predictions using the GLMnet Model "],
["read-the-data.html", "Chapter 2 Read the Data", " Chapter 2 Read the Data We read the data from the train and the test datasets. library(tidyverse) library(tidytext) library(stringr) library(knitr) library(kableExtra) library(&#39;wordcloud&#39;) library(igraph) library(ggraph) library(tm) library(topicmodels) library(caret) library(syuzhet) library(text2vec) library(data.table) library(&quot;readr&quot;) library(glmnet) rm(list=ls()) fillColor = &quot;#FFA07A&quot; fillColor2 = &quot;#F1C40F&quot; train = read_csv(&quot;input/train.csv&quot;) test = read_csv(&quot;input/test.csv&quot;) "],
["add-feature-number-of-words.html", "Chapter 3 Add Feature Number of Words", " Chapter 3 Add Feature Number of Words We add a Feature, Number of Words for each line to the Train and Test data sets train$len = str_count(train$text) test$len = str_count(test$text) "],
["peek-into-the-data.html", "Chapter 4 Peek into the Data", " Chapter 4 Peek into the Data We peek into the train data in the table below. kable(head(train),&quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% scroll_box(width = &quot;800px&quot;) id text author len id26305 This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall. EAP 231 id17569 It never once occurred to me that the fumbling might be a mere mistake. HPL 71 id11008 In his left hand was a gold snuff box, from which, as he capered down the hill, cutting all manner of fantastic steps, he took snuff incessantly with an air of the greatest possible self satisfaction. EAP 200 id27763 How lovely is spring As we looked from Windsor Terrace on the sixteen fertile counties spread beneath, speckled by happy cottages and wealthier towns, all looked as in former years, heart cheering and fair. MWS 206 id12958 Finding nothing else, not even gold, the Superintendent abandoned his attempts; but a perplexed look occasionally steals over his countenance as he sits thinking at his desk. HPL 174 id22965 A youth passed in solitude, my best years spent under your gentle and feminine fosterage, has so refined the groundwork of my character that I cannot overcome an intense distaste to the usual brutality exercised on board ship: I have never believed it to be necessary, and when I heard of a mariner equally noted for his kindliness of heart and the respect and obedience paid to him by his crew, I felt myself peculiarly fortunate in being able to secure his services. MWS 468 "],
["length-comparison.html", "Chapter 5 Length Comparison", " Chapter 5 Length Comparison We examine the median length of the sentences by the different authors and plot in a flipped bar plot. HP Lovecraft writes long sentences with the highest number of words per sentence.Edgar Allen Poe writes short sentences compared to the other Two authors. train %&gt;% group_by(author) %&gt;% summarise(CountMedian = median(len,na.rm = TRUE)) %&gt;% ungroup() %&gt;% mutate(author = reorder(author,CountMedian)) %&gt;% ggplot(aes(x = author,y = CountMedian)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor2) + geom_text(aes(x = author, y = 1, label = paste0(&quot;(&quot;,CountMedian,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;author&#39;, y = &#39;Count&#39;, title = &#39;author and Count&#39;) + coord_flip() + theme_bw() "],
["words-length-distribution.html", "Chapter 6 Words Length Distribution 6.1 Words Length Distribution Plot 2", " Chapter 6 Words Length Distribution We examine the number of words written by the author in a single sentence with the histogram. Unfortunately the plot does not reveal much. Therefore we would like to change the x-axis so that we can have a better plot. train %&gt;% ggplot(aes(x = len, fill = author)) + geom_histogram() + scale_fill_manual( values = c(&quot;red&quot;,&quot;blue&quot;,&quot;orange&quot;) ) + facet_wrap(~author) + labs(x= &#39;Word Length&#39;,y = &#39;Count&#39;, title = paste(&quot;Distribution of&quot;, &#39; Word Length &#39;)) + theme_bw() 6.1 Words Length Distribution Plot 2 We limit the word length to 100 and investigate the distribution.We notice that HP Lovecraft and Mary Wollstonecraft Shelley have a lot of sentences with word length in the range 75 - 100. train %&gt;% ggplot(aes(x = len, fill = author)) + geom_histogram() + scale_x_continuous(limits = c(15,100)) + scale_fill_manual( values = c(&quot;red&quot;,&quot;blue&quot;,&quot;orange&quot;) ) + facet_wrap(~author) + labs(x= &#39;Word Length&#39;,y = &#39;Count&#39;, title = paste(&quot;Distribution of&quot;, &#39; Word Length &#39;)) + theme_bw() "],
["top-twenty-most-common-words.html", "Chapter 7 Top Twenty most Common Words 7.1 WordCloud of the Common Words 7.2 WordCloud of HPL 7.3 BarPlot for words of HPL 7.4 WordCloud of MWS 7.5 BarPlot for words of MWS 7.6 WordCloud of EAP 7.7 BarPlot for words of EAP", " Chapter 7 Top Twenty most Common Words We examine the Top Twenty Most Common words and show them in a bar graph. Several words which occur a lot are time , life , found , night, eyes, day , death, mind , heard createBarPlotCommonWords = function(train,title) { train %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% head(10) %&gt;% ggplot(aes(x = word,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = word, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Word&#39;, y = &#39;Word Count&#39;, title = title) + coord_flip() + theme_bw() } createBarPlotCommonWords(train,&#39;Top 10 most Common Words&#39;) 7.1 WordCloud of the Common Words A word cloud is a graphical representation of frequently used words in the text. The height of each word in this picture is an indication of frequency of occurrence of the word in the entire text. createWordCloud = function(train) { train %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% head(30) %&gt;% with(wordcloud(word, n, max.words = 30,colors=brewer.pal(8, &quot;Dark2&quot;))) } createWordCloud(train) 7.2 WordCloud of HPL Time , night, strange, found, house are the most common words written by HP Lovecraft. createWordCloud(train %&gt;% filter(author == &#39;HPL&#39;)) 7.3 BarPlot for words of HPL createBarPlotCommonWords(train %&gt;% filter(author == &#39;HPL&#39;),&#39;Top 10 most Common Words of HPL&#39;) 7.4 WordCloud of MWS Raymond,heart, love, time and eyes are the most common words written by Mary Wollstonecraft Shelley createWordCloud(train %&gt;% filter(author == &#39;MWS&#39;)) 7.5 BarPlot for words of MWS createBarPlotCommonWords(train %&gt;% filter(author == &#39;MWS&#39;),&#39;Top 10 most Common Words of MWS&#39;) 7.6 WordCloud of EAP Found, time, eyes, length, head, day are the most common words written by Edgar Allan Poe. createWordCloud(train %&gt;% filter(author == &#39;EAP&#39;)) 7.7 BarPlot for words of EAP createBarPlotCommonWords(train %&gt;% filter(author == &#39;EAP&#39;),&#39;Top 10 most Common Words of EAP&#39;) "],
["tf-idf.html", "Chapter 8 TF-IDF 8.1 The Math 8.2 Twenty Most Important words 8.3 Word Cloud for the Most Important Words", " Chapter 8 TF-IDF We wish to find out the important words which are written by the authors. Example for your young child , the most important word is mom. Example for a bar tender , important words would be related to drinks. We would explore this using a fascinating concept known as Term Frequency - Inverse Document Frequency. Quite a mouthful, but we will unpack it and clarify each and every term. A document in this case is the set of lines written by an author. Therefore we have different documents for each Author. From the book 5 Algorithms Every Web Developer Can Use and Understand TF-IDF computes a weight which represents the importance of a term inside a document. It does this by comparing the frequency of usage inside an individual document as opposed to the entire data set (a collection of documents). The importance increases proportionally to the number of times a word appears in the individual document itself–this is called Term Frequency. However, if multiple documents contain the same word many times then you run into a problem. That’s why TF-IDF also offsets this value by the frequency of the term in the entire document set, a value called Inverse Document Frequency. 8.1 The Math TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document) IDF(t) = log_e(Total number of documents / Number of documents with term t in it). Value = TF * IDF 8.2 Twenty Most Important words Here using TF-IDF , we investigate the Twenty Most Important words trainWords &lt;- train %&gt;% unnest_tokens(word, text) %&gt;% count(author, word, sort = TRUE) %&gt;% ungroup() total_words &lt;- trainWords %&gt;% group_by(author) %&gt;% summarize(total = sum(n)) trainWords &lt;- left_join(trainWords, total_words) #Now we are ready to use the bind_tf_idf which computes the tf-idf for each term. trainWords &lt;- trainWords %&gt;% filter(!is.na(author)) %&gt;% bind_tf_idf(word, author, n) plot_trainWords &lt;- trainWords %&gt;% arrange(desc(tf_idf)) %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) plot_trainWords %&gt;% top_n(20) %&gt;% ggplot(aes(word, tf_idf)) + geom_col(fill = fillColor) + labs(x = NULL, y = &quot;tf-idf&quot;) + coord_flip() + theme_bw() 8.2.1 Twenty most important words HPL plot_trainWords %&gt;% filter(author == &#39;HPL&#39;) %&gt;% top_n(20) %&gt;% ggplot(aes(word, tf_idf)) + geom_col(fill = fillColor2) + labs(x = NULL, y = &quot;tf-idf&quot;) + coord_flip() + theme_bw() 8.2.2 Twenty most important words EAP plot_trainWords %&gt;% filter(author == &#39;EAP&#39;) %&gt;% top_n(20) %&gt;% ggplot(aes(word, tf_idf)) + geom_col(fill = fillColor) + labs(x = NULL, y = &quot;tf-idf&quot;) + coord_flip() + theme_bw() 8.2.3 Twenty most important words MWS plot_trainWords %&gt;% filter(author == &#39;MWS&#39;) %&gt;% top_n(20) %&gt;% ggplot(aes(word, tf_idf, fill = author)) + geom_col() + labs(x = NULL, y = &quot;tf-idf&quot;) + coord_flip() + theme_bw() 8.3 Word Cloud for the Most Important Words We show the Hundred most important words. This Word Cloud is based on the TF- IDF scores. Higher the score, bigger is the size of the text. plot_trainWords %&gt;% with(wordcloud(word, tf_idf, max.words = 100,colors=brewer.pal(8, &quot;Dark2&quot;))) "],
["most-common-bigrams.html", "Chapter 9 Most Common Bigrams", " Chapter 9 Most Common Bigrams A Bigram is a collection of Two words. We examine the most common Bigrams and plot them in a bar plot. count_bigrams &lt;- function(dataset) { dataset %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;% separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) %&gt;% count(word1, word2, sort = TRUE) } visualize_bigrams &lt;- function(bigrams) { set.seed(2016) a &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;)) bigrams %&gt;% graph_from_data_frame() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a) + geom_node_point(color = &quot;lightblue&quot;, size = 5) + geom_node_text(aes(label = name), vjust = 1, hjust = 1) + theme_void() } visualize_bigrams_individual &lt;- function(bigrams) { set.seed(2016) a &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;)) bigrams %&gt;% graph_from_data_frame() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a,end_cap = circle(.07, &#39;inches&#39;)) + geom_node_point(color = &quot;lightblue&quot;, size = 5) + geom_node_text(aes(label = name), vjust = 1, hjust = 1) + theme_void() } train %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;% separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) %&gt;% unite(bigramWord, word1, word2, sep = &quot; &quot;) %&gt;% group_by(bigramWord) %&gt;% tally() %&gt;% ungroup() %&gt;% arrange(desc(n)) %&gt;% mutate(bigramWord = reorder(bigramWord,n)) %&gt;% head(10) %&gt;% ggplot(aes(x = bigramWord,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor2) + geom_text(aes(x = bigramWord, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Bigram&#39;, y = &#39;Count&#39;, title = &#39;Bigram and Count&#39;) + coord_flip() + theme_bw() "],
["most-common-trigrams.html", "Chapter 10 Most Common Trigrams", " Chapter 10 Most Common Trigrams A Trigram is a collection of Three words. We examine the most common Trigrams and plot them in a bar plot. train %&gt;% unnest_tokens(trigram, text, token = &quot;ngrams&quot;, n = 3) %&gt;% separate(trigram, c(&quot;word1&quot;, &quot;word2&quot;,&quot;word3&quot;), sep = &quot; &quot;) %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word, !word3 %in% stop_words$word) %&gt;% unite(trigramWord, word1, word2, word3,sep = &quot; &quot;) %&gt;% group_by(trigramWord) %&gt;% tally() %&gt;% ungroup() %&gt;% arrange(desc(n)) %&gt;% mutate(trigramWord = reorder(trigramWord,n)) %&gt;% head(10) %&gt;% ggplot(aes(x = trigramWord,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor2) + geom_text(aes(x = trigramWord, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Trigram&#39;, y = &#39;Count&#39;, title = &#39;Trigram and Count&#39;) + coord_flip() + theme_bw() "],
["relationship-among-words.html", "Chapter 11 Relationship among words", " Chapter 11 Relationship among words Til now, we have explored the most important words for a author. Now, we will explore the relationship between words. trainWords &lt;- train %&gt;% count_bigrams() trainWords %&gt;% filter(n &gt; 10) %&gt;% visualize_bigrams() The above infographic shows the words which follow another word. "],
["sentiment-analysis.html", "Chapter 12 Sentiment Analysis 12.1 Postive Authors and Not so Positive Authors 12.2 Postive and Not So Postive Words of Authors 12.3 Postive and Not So Postive Words of Author HPL 12.4 Postive and Not So Postive Words of Author EAP 12.5 Postive and Not So Postive Words of Author MWS", " Chapter 12 Sentiment Analysis 12.1 Postive Authors and Not so Positive Authors We investigate how often positive and negative words occurred in the text written by the authors. Which author was the most positive or negative overall? We will use the AFINN sentiment lexicon, which provides numeric positivity scores for each word, and visualize it with a bar plot. Edgar Allen Poe and Mary Wollstonecraft Shelley are positive authors HP Lovecraft is unfortunately a negative author as explained through a bar plot. We need to go into detail why HP Lovecraft is a negative author. visualize_sentiments &lt;- function(SCWords) { SCWords_sentiments &lt;- SCWords %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(author) %&gt;% summarize(score = sum(score * n) / sum(n)) %&gt;% arrange(desc(score)) SCWords_sentiments %&gt;% mutate(author = reorder(author, score)) %&gt;% ggplot(aes(author, score, fill = score &gt; 0)) + geom_col(show.legend = TRUE) + coord_flip() + ylab(&quot;Average sentiment score&quot;) + theme_bw() } trainWords &lt;- train %&gt;% unnest_tokens(word, text) %&gt;% count(author, word, sort = TRUE) %&gt;% ungroup() visualize_sentiments(trainWords) 12.2 Postive and Not So Postive Words of Authors The following graph shows the Twenty high positive and the negative words positiveWordsBarGraph &lt;- function(SC) { contributions &lt;- SC %&gt;% unnest_tokens(word, text) %&gt;% count(author, word, sort = TRUE) %&gt;% ungroup() %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(word) %&gt;% summarize(occurences = n(), contribution = sum(score)) contributions %&gt;% top_n(20, abs(contribution)) %&gt;% mutate(word = reorder(word, contribution)) %&gt;% head(20) %&gt;% ggplot(aes(word, contribution, fill = contribution &gt; 0)) + geom_col(show.legend = FALSE) + coord_flip() + theme_bw() } positiveWordsBarGraph(train) 12.3 Postive and Not So Postive Words of Author HPL trainHPL = train %&gt;% filter(author == &#39;HPL&#39;) positiveWordsBarGraph(trainHPL) 12.4 Postive and Not So Postive Words of Author EAP trainEAP = train %&gt;% filter(author == &#39;EAP&#39;) positiveWordsBarGraph(trainEAP) 12.5 Postive and Not So Postive Words of Author MWS trainMWS = train %&gt;% filter(author == &#39;MWS&#39;) positiveWordsBarGraph(trainMWS) "],
["sentiment-analysis-using-nrc-sentiment-lexicon.html", "Chapter 13 Sentiment Analysis using NRC Sentiment lexicon 13.1 Sentiment Analysis Words - Fear 13.2 Fear Word Cloud - MWP 13.3 Sentiment Analysis Words - Surprise 13.4 Surprise Word Cloud - MWP 13.5 Sentiment Analysis Words - Joy 13.6 Joy Word Cloud - MWP", " Chapter 13 Sentiment Analysis using NRC Sentiment lexicon We examine the following sentiments using NRC Sentiment lexicon Fear Surprise Joy Mary Wollstonecraft Shelley is the most Fearful and most Surprising and most Joyful author. Edgar Allen Poe is the least Fearful author. HP Lovecraft is the least Surprising author. HP Lovecraft is the least Joyful author. 13.1 Sentiment Analysis Words - Fear The plot shows the authors with the Count of fear words. plotEmotions = function(emotion,fillColor = fillColor2) { nrcEmotions = get_sentiments(&quot;nrc&quot;) %&gt;% filter(sentiment == emotion) train %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% inner_join(nrcEmotions) %&gt;% group_by(author) %&gt;% summarise(Count = n()) %&gt;% ungroup() %&gt;% mutate(author = reorder(author,Count)) %&gt;% ggplot(aes(x = author,y = Count)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = author, y = 1, label = paste0(&quot;(&quot;,Count,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;author&#39;, y = &#39;Count&#39;, title = paste0(&#39;Author and &#39;,emotion,&#39; Words &#39;)) + coord_flip() + theme_bw() } plotEmotions(&quot;fear&quot;) 13.2 Fear Word Cloud - MWP The following table and word cloud shows the fear words written by MWP , the most fearful author. getEmotionalWords = function(emotion,author) { nrcEmotions = get_sentiments(&quot;nrc&quot;) %&gt;% filter(sentiment == emotion) emotionalWords = train %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% filter(author == author) %&gt;% inner_join(nrcEmotions) %&gt;% group_by(word) %&gt;% summarise(Count = n()) %&gt;% arrange(desc(Count)) return(emotionalWords) } FearWordsMWS = getEmotionalWords(&#39;fear&#39;,&#39;MWS&#39;) kable(head(FearWordsMWS),&quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% scroll_box(width = &quot;800px&quot;) word Count death 380 fear 240 horror 198 doubt 159 terrible 146 change 136 wordcloud(FearWordsMWS$word, FearWordsMWS$Count, max.words = 30,colors=brewer.pal(8, &quot;Dark2&quot;)) 13.3 Sentiment Analysis Words - Surprise The plot shows the authors with the Count of Surprise words. plotEmotions(&quot;surprise&quot;,fillColor) 13.4 Surprise Word Cloud - MWP The following table and word cloud shows the surprising words written by MWP , the most surprising author. SurpriseWordsMWS = getEmotionalWords(&#39;surprise&#39;,&#39;MWS&#39;) kable(head(SurpriseWordsMWS),&quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% scroll_box(width = &quot;800px&quot;) word Count death 380 horror 198 hope 195 sun 167 wild 157 suddenly 151 wordcloud(SurpriseWordsMWS$word, SurpriseWordsMWS$Count, max.words = 30,colors=brewer.pal(8, &quot;Dark2&quot;)) 13.5 Sentiment Analysis Words - Joy The plot shows the authors with the Count of Joy words. plotEmotions(&quot;joy&quot;,fillColor2) 13.6 Joy Word Cloud - MWP The following table and word cloud shows the joy words written by MWP , the most joy author. JoyWordsMWS = getEmotionalWords(&#39;joy&#39;,&#39;MWS&#39;) kable(head(JoyWordsMWS),&quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% scroll_box(width = &quot;800px&quot;) word Count found 559 love 331 friend 270 hope 195 sun 167 beauty 154 wordcloud(JoyWordsMWS$word, JoyWordsMWS$Count, max.words = 30,colors=brewer.pal(8, &quot;Dark2&quot;)) "],
["positive-and-not-so-postive-lines.html", "Chapter 14 Positive and Not So Postive Lines", " Chapter 14 Positive and Not So Postive Lines sentiment_lines = train %&gt;% unnest_tokens(word, text) %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(id) %&gt;% summarize(sentiment = mean(score), words = n()) The sentences having top Ten positive sentiments are id sentiment words text author len id05517 5 1 The apartment was superb. EAP 25 id07548 5 1 My original soul seemed, at once, to take its flight from my body and a more than fiendish malevolence, gin nurtured, thrilled every fibre of my frame. EAP 151 id10196 5 1 “I thought so I knew it hurrah” vociferated Legrand, letting the negro go, and executing a series of curvets and caracols, much to the astonishment of his valet, who, arising from his knees, looked, mutely, from his master to myself, and then from myself to his master. EAP 269 id25394 5 1 “Superb physiologist” said the Westminster. EAP 43 id00752 4 1 Then I would hasten to my desk, weave the new found web of mind in firm texture and brilliant colours, leaving the fashioning of the material to a calmer moment. MWS 161 id00880 4 1 The Automaton does not invariably win the game. EAP 47 id01194 4 1 “Wonderful genius” said the Quarterly. EAP 38 id01391 4 1 With the quick sensibility peculiar to his temperament, he perceived his power in the brilliant circle to be on the wane. MWS 121 id01674 4 1 Ibid’s masterpiece, on the other hand, was the famous Op. HPL 57 id01902 4 1 The ‘Oil of Bob’ is the title of this masterpiece of eloquence and art. EAP 71 id01957 4 1 As soon as I sufficiently recovered my senses to comprehend the terrific predicament in which I stood or rather hung, I exerted all the power of my lungs to make that predicament known to the æronaut overhead. EAP 209 id02055 4 1 “Astonishingly,” said the second; “still quite a brilliant air, but art will do wonders. EAP 88 id02141 4 1 And now for the first time my memory records verbal discourse, Warren addressing me at length in his mellow tenor voice; a voice singularly unperturbed by our awesome surroundings. HPL 180 id02150 4 1 The general burst of terrific grandeur was all that I beheld. EAP 61 id03133 4 1 It appears to me a miracle of miracles that our enormous bulk is not swallowed up at once and forever. EAP 102 id04370 4 1 Phantasies such as these, presenting themselves at night, extended their terrific influence far into my waking hours. EAP 117 id04796 4 1 But here’s a funny thing. HPL 25 id04987 4 1 But his wife had said she found a funny tin thing in one of the beds when she fixed the rooms at noon, and maybe that was it. HPL 125 id05161 4 1 Some miracle might have produced it, yet the stages of the discovery were distinct and probable. MWS 96 id05414 4 1 Here he pointed to a fabulous creature of the artist, which one might describe as a sort of dragon with the head of an alligator. HPL 129 id05512 4 1 The starry sky, the sea, and every sight afforded by these wonderful regions seem still to have the power of elevating his soul from earth. MWS 139 id05994 4 1 Still others, including Joe himself, have theories too wild and fantastic for sober credence. HPL 93 id06517 4 1 The galvanic battery was applied, and he suddenly expired in one of those ecstatic paroxysms which, occasionally, it superinduces. EAP 130 id07409 4 1 Gilman came from Haverhill, but it was only after he had entered college in Arkham that he began to connect his mathematics with the fantastic legends of elder magic. HPL 166 id07919 4 1 There were secrets, said the peasants, which must not be uncovered; secrets that had lain hidden since the plague came to the children of Partholan in the fabulous years beyond history. HPL 185 id08642 4 1 But for one thing he would have been completely triumphant. MWS 59 id09430 4 1 At a terrific height directly above us, and upon the very verge of the precipitous descent, hovered a gigantic ship of, perhaps, four thousand tons. EAP 148 id10453 4 1 It is of a brilliant gold color about the size of a large hickory nut with two jet black spots near one extremity of the back, and another, somewhat longer, at the other. EAP 170 id10612 4 1 I heard of the slothful Asiatics, of the stupendous genius and mental activity of the Grecians, of the wars and wonderful virtue of the early Romans of their subsequent degenerating of the decline of that mighty empire, of chivalry, Christianity, and kings. MWS 257 id10741 4 1 I could scarcely contain my feelings of triumph. EAP 48 id11420 4 1 And thus were produced a multitude of gaudy and fantastic appearances. EAP 70 id12199 4 1 You never saw a more brilliant metallic lustre than the scales emit but of this you cannot judge till tomorrow. EAP 111 id12895 4 1 When rocked by the waves of the lake my spirits rose in triumph as a horseman feels with pride the motions of his high fed steed. MWS 129 id13372 4 2 The principle being discovered by which a machine can be made to play a game of chess, an extension of the same principle would enable it to win a game a farther extension would enable it to win all games that is, to beat any possible game of an antagonist. EAP 257 id14028 4 1 And at such moments was her beauty in my heated fancy thus it appeared perhaps the beauty of beings either above or apart from the earth the beauty of the fabulous Houri of the Turk. EAP 182 id14063 4 1 It is rumoured in Ulthar, beyond the river Skai, that a new king reigns on the opal throne in Ilek Vad, that fabulous town of turrets atop the hollow cliffs of glass overlooking the twilight sea wherein the bearded and finny Gnorri build their singular labyrinths, and I believe I know how to interpret this rumour. HPL 315 id14303 4 1 I displayed a peculiar erudition utterly unlike the fantastic, monkish lore over which I had pored in youth; and covered the flyleaves of my books with facile impromptu epigrams which brought up suggestions of Gay, Prior, and the sprightliest of the Augustan wits and rimesters. HPL 278 id14573 4 1 For your life you could not have found a fault with its wonderful proportion. EAP 77 id17723 4 1 Even Perdita will rejoice. MWS 26 id17854 4 1 In a moment of fantastic whim I whispered questions to the reddening ears; questions of other worlds of which the memory might still be present. HPL 144 id18191 4 1 In the midst of these reflections, as if dramatically arranged to intensify them, there fell near by a terrific bolt of lightning followed by the sound of sliding earth. HPL 169 id18900 4 1 Once a terrific flash and peal shook the frail house to its foundations, but the whisperer seemed not to notice it. HPL 115 id18936 4 1 Its productions and features may be without example, as the phenomena of the heavenly bodies undoubtedly are in those undiscovered solitudes. MWS 141 id19544 4 1 As he walked among other men he seemed encompassed with a heavenly halo that divided him from and lifted him above them. MWS 120 id19712 4 1 Thus it was that, by a master stroke of genius, I at length consummated my triumphs by “putting money in my purse,” and thus may be said really and fairly to have commenced that brilliant and eventful career which rendered me illustrious, and which now enables me to say, with Chateaubriand, “I have made history” “I’ai fait l’histoire.” EAP 337 id19994 4 1 The resources of his mind on this occasion were truly astonishing: his conversation was full of imagination; and very often, in imitation of the Persian and Arabic writers, he invented tales of wonderful fancy and passion. MWS 222 id20925 4 1 Wonderful likewise were the gardens made by Zokkar the olden king. HPL 66 id20938 4 1 A moment more and the old walls again met my sight, while over them hovered a murky cloud; fragments of buildings whirled above, half seen in smoke, while flames burst out beneath, and continued explosions filled the air with terrific thunders. MWS 244 id21073 4 1 The whole cohort now remained at a standstill, and as the torches faded I watched what I thought were fantastic shadows outlined in the sky by the spectral luminosity of the Via Lactea as it flowed through Perseus, Cassiopeia, Cepheus, and Cygnus. HPL 247 id21163 4 1 Then they all sprang at him and tore him to pieces before my eyes, bearing the fragments away into that subterranean vault of fabulous abominations. HPL 148 id21978 4 1 But more wonderful than the lore of old men and the lore of books is the secret lore of ocean. HPL 94 id22192 4 1 Overjoyed at this discovery, he hastened to the house, which was situated in a mean street near the Reuss. MWS 106 id22670 4 1 Only at the twelfth was the triumph complete. EAP 45 id22754 4 1 While they were talking Desrochers dropped in to say that he had heard a terrific clattering overhead in the dark small hours. HPL 126 id23837 4 1 I frequently engaged him in play, and contrived, with the gambler’s usual art, to let him win considerable sums, the more effectually to entangle him in my snares. EAP 163 id24090 4 1 Curtis Whateley was only just regaining consciousness when the Arkham men came slowly down the mountain in the beams of a sunlight once more brilliant and untainted. HPL 165 id24735 4 1 And yet I saw them in a limitless stream flopping, hopping, croaking, bleating surging inhumanly through the spectral moonlight in a grotesque, malignant saraband of fantastic nightmare. HPL 186 id27441 4 1 I will therefore guess even;’ he guesses even, and wins. EAP 56 id27698 4 1 Yet there have been many and wonderful automata. EAP 48 The sentences having top Ten NOT so positive sentiments are ## Joining, by = &quot;id&quot; id sentiment words text author len id05489 -5 1 We shall see that at which dogs howl in the dark, and that at which cats prick up their ears after midnight. HPL 108 id16045 -5 1 How did he know the time when Nahab and her acolyte were due to bear the brimming bowl which would follow the black cock and the black goat? HPL 140 id00307 -4 1 It rang on my ears long and heavily; the mountains re echoed it, and I felt as if all hell surrounded me with mockery and laughter. MWS 131 id00476 -4 1 and was he not consequently damned? EAP 35 id02649 -4 1 You have given me new wants and now your trifle with me as if my heart were as whole as yours, as if I were not in truth a shorn lamb thrust out on the bleak hill side, tortured by every blast. MWS 193 id06874 -4 1 The very beauty of the Grecian climate, during the season of spring, added torture to her sensations. MWS 101 id08709 -4 1 “Ass” said the fourth. EAP 22 id09729 -4 1 There was a secret which even torture could not extract. HPL 56 id11422 -4 1 My companion looked eagerly from one bed to the other, till at the end of the ward she espied, on a wretched bed, a squalid, haggard creature, writhing under the torture of disease. MWS 181 id11965 -4 1 Perdita, who then resided with Evadne, saw the torture that Adrian endured. MWS 75 id15587 -4 1 Raymond staggered forth from this scene, as a man might do, who had been just put to the torture, and looked forward to when it would be again inflicted. MWS 153 id16281 -4 1 I heard many things in hell. EAP 28 id16535 -4 1 I might be driven into the wide Atlantic and feel all the tortures of starvation or be swallowed up in the immeasurable waters that roared and buffeted around me. MWS 162 id16780 -4 1 The tortures endured, however, were indubitably quite equal for the time, to those of actual sepulture. EAP 103 id21653 -4 1 I don’t believe anybody since Goya could put so much of sheer hell into a set of features or a twist of expression. HPL 115 id21796 -4 1 This idea was torture to him. MWS 29 id22475 -4 1 In the former, the torture of meditation was excessive in the latter, supreme. EAP 78 id22542 -4 1 Molehills . . . the damned place must be honeycombed . . . HPL 58 id23474 -4 1 “The full moon damn ye ye . . . HPL 31 "],
["feature-sentiment-score.html", "Chapter 15 Feature Sentiment Score", " Chapter 15 Feature Sentiment Score We calculate the sentiment score for each line thru the following code. getSentimentScore = function(train) { sentiment_lines = train %&gt;% unnest_tokens(word, text) %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(id) %&gt;% summarize(sentiment = mean(score)) sentiment_lines = sentiment_lines %&gt;% right_join(train, by = &quot;id&quot;) sentiment_lines = sentiment_lines %&gt;% mutate(sentiment = ifelse(is.na(sentiment),0,sentiment)) return(sentiment_lines$sentiment) } "],
["feature-nrc-sentiments.html", "Chapter 16 Feature NRC Sentiments", " Chapter 16 Feature NRC Sentiments We create the NRC Sentiments in the following section. We display the sentiment scores for Six lines of the train dataset. sentimentsTrain = get_nrc_sentiment(train$text) sentimentsTest = get_nrc_sentiment(test$text) kable(head(sentimentsTrain),&quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;, &quot;condensed&quot;, &quot;responsive&quot;)) %&gt;% scroll_box(width = &quot;800px&quot;) anger anticipation disgust fear joy sadness surprise trust negative positive 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 2 0 0 3 1 1 2 0 5 1 0 0 1 0 1 0 0 2 1 3 4 2 3 3 0 2 6 4 9 "],
["he-or-she-analysis.html", "Chapter 17 He or She Analysis 17.1 Gender associated verbs", " Chapter 17 He or She Analysis We examine the words which start with he or she. This section draws inspiration from the blog post by David Robinson in his writeup train %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;% separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(word1 %in% c(&quot;he&quot;, &quot;she&quot;)) ## # A tibble: 5,680 x 5 ## id author len word1 word2 ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 id00004 EAP 134 he might ## 2 id00004 EAP 134 he necessarily ## 3 id00017 EAP 469 he makes ## 4 id00029 MWS 115 he entered ## 5 id00035 HPL 75 he was ## 6 id00036 HPL 201 he had ## 7 id00037 MWS 274 he owned ## 8 id00037 MWS 274 he the ## 9 id00043 HPL 167 he absorbed ## 10 id00045 MWS 237 he found ## # ... with 5,670 more rows 17.1 Gender associated verbs Which words were most shifted towards occurring after “he” or “she”? We’ll filter for words that appeared at least 20 times. train %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;% separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(word1 %in% c(&quot;he&quot;, &quot;she&quot;)) %&gt;% count(word1,word2) %&gt;% spread(word1, n, fill = 0) %&gt;% mutate(total = he + she, he = (he + 1) / sum(he + 1), she = (she + 1) / sum(she + 1), log_ratio = log2(she / he), abs_ratio = abs(log_ratio)) %&gt;% arrange(desc(log_ratio)) %&gt;% filter(!word2 %in% c(&quot;himself&quot;, &quot;herself&quot;), !word2 %in% stop_words$word, total&gt;= 20) %&gt;% group_by(direction = ifelse(log_ratio &gt; 0, &#39;More &quot;she&quot;&#39;, &quot;More &#39;he&#39;&quot;)) %&gt;% top_n(15, abs_ratio) %&gt;% ungroup() %&gt;% mutate(word2 = reorder(word2, log_ratio)) %&gt;% ggplot(aes(word2, log_ratio, fill = direction)) + geom_col() + coord_flip() + labs(x = &quot;&quot;, y = &#39;Relative appearance after &quot;she&quot; compared to &quot;he&quot;&#39;, fill = &quot;&quot;, title = &quot;Gender associated with Verbs &quot;) + scale_y_continuous(labels = c(&quot;4X&quot;, &quot;2X&quot;, &quot;Same&quot;, &quot;2X&quot;), breaks = seq(-2, 1)) + guides(fill = guide_legend(reverse = TRUE)) + theme_bw() She cried , She loved , She died ,She heard is common while He told, He spoke, He sat, He wished , He found are common "],
["document-term-matrix.html", "Chapter 18 Document Term Matrix", " Chapter 18 Document Term Matrix Document Term Matrix creates a Bag of Words and does the following operations * make the words lower remove punctuation remove stopwords of English stem the bag of Words. The tm package provides the stemDocument() function to get to a word’s root makeDTM &lt;- function(train) { corpus = Corpus(VectorSource(train$text)) # Pre-process data corpus &lt;- tm_map(corpus, tolower) corpus &lt;- tm_map(corpus, removePunctuation) corpus &lt;- tm_map(corpus, removeWords, stopwords(&quot;english&quot;)) corpus &lt;- tm_map(corpus, stemDocument) dtm = DocumentTermMatrix(corpus) # Remove sparse terms dtm = removeSparseTerms(dtm, 0.997) # Create data frame labeledTerms = as.data.frame(as.matrix(dtm)) return(labeledTerms) } Topic modeling is a method for unsupervised classification of documents, similar to clustering on numeric data, which finds natural groups of items even when we’re not sure what we’re looking for. Latent Dirichlet allocation (LDA) is a particularly popular method for fitting a topic model. It treats each document as a mixture of topics, and each topic as a mixture of words. This allows documents to “overlap” each other in terms of content, rather than being separated into discrete groups, in a way that mirrors typical use of natural language. labeledTerms4LDA = makeDTM(train) labeledTerms4LDA = labeledTerms4LDA[rowSums(abs(labeledTerms4LDA)) != 0,] spooky_lda &lt;- LDA(labeledTerms4LDA, k = 9, control = list(seed = 13)) spooky_lda ## A LDA_VEM topic model with 9 topics. #The tidytext package provides this method for extracting the per-topic-per-word probabilities, # called β (“beta”), from the model spooky_topics &lt;- tidy(spooky_lda, matrix = &quot;beta&quot;) spooky_top_terms &lt;- spooky_topics %&gt;% group_by(topic) %&gt;% top_n(10, beta) %&gt;% ungroup() %&gt;% arrange(topic, -beta) spooky_top_terms %&gt;% mutate(term = reorder(term, beta)) %&gt;% ggplot(aes(term, beta, fill = factor(topic))) + geom_col(show.legend = FALSE) + facet_wrap(~ topic, scales = &quot;free&quot;) + coord_flip() + theme_bw() This visualization lets us understand the Nine topics that were extracted from the Words. Some of the words occur in more than one topic. "],
["modelling-with-xgboost.html", "Chapter 19 Modelling with XGBoost 19.1 Add features 19.2 Creating the XGBoost Model", " Chapter 19 Modelling with XGBoost We try to predict whether the lines are written by a specific author. We do Cross Validation using Caret package.Lastly we wish to examine the feature importance of the variables. This is shown in the flipped bar chart. We then use the model to predict the authors. makeFeatures &lt;- function(train) { labeledTerms = makeDTM(train) ## Preparing the features for the XGBoost Model features &lt;- colnames(labeledTerms) for (f in features) { if ((class(labeledTerms[[f]])==&quot;factor&quot;) || (class(labeledTerms[[f]])==&quot;character&quot;)) { levels &lt;- unique(labeledTerms[[f]]) labeledTerms[[f]] &lt;- as.numeric(factor(labeledTerms[[f]], levels=levels)) } } return(labeledTerms) } labeledTerms = makeFeatures(train) labeledTermsTest = makeFeatures(test) colnamesSame = intersect(colnames(labeledTerms),colnames(labeledTermsTest)) labeledTerms = labeledTerms[ , (colnames(labeledTerms) %in% colnamesSame)] labeledTermsTest = labeledTermsTest[ , (colnames(labeledTermsTest) %in% colnamesSame)] 19.1 Add features We add the following features to the model Number of words in the line Sentiment Score per line labeledTerms$len = train$len labeledTermsTest$len = test$len labeledTerms$sentiScore = getSentimentScore(train) labeledTermsTest$sentiScore = getSentimentScore(test) 19.2 Creating the XGBoost Model labeledTerms$author = as.factor(train$author) levels(labeledTerms$author) = make.names(unique(labeledTerms$author)) formula = author ~ . #Please uncomment if you want to do Cross Validation # fitControl &lt;- trainControl(method=&quot;cv&quot;,number = 5,classProbs=TRUE, summaryFunction=mnLogLoss) # # xgbGrid &lt;- expand.grid(nrounds = 500, # max_depth = 3, # eta = .05, # gamma = 0, # colsample_bytree = .8, # min_child_weight = 1, # subsample = 1) fitControl &lt;- trainControl(method=&quot;none&quot;,classProbs=TRUE, summaryFunction=mnLogLoss) xgbGrid &lt;- expand.grid(nrounds = 500, max_depth = 3, eta = .05, gamma = 0, colsample_bytree = .8, min_child_weight = 1, subsample = 1) set.seed(13) AuthorXGB = train(formula, data = labeledTerms, method = &quot;xgbTree&quot;,trControl = fitControl, tuneGrid = xgbGrid,na.action = na.pass,metric=&quot;LogLoss&quot;, maximize=FALSE) importance = varImp(AuthorXGB) varImportance &lt;- data.frame(Variables = row.names(importance[[1]]), Importance = round(importance[[1]]$Overall,2)) # Create a rank variable based on importance rankImportance &lt;- varImportance %&gt;% mutate(Rank = paste0(&#39;#&#39;,dense_rank(desc(Importance)))) %&gt;% head(20) rankImportancefull = rankImportance ggplot(rankImportance, aes(x = reorder(Variables, Importance), y = Importance)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor) + geom_text(aes(x = Variables, y = 1, label = Rank), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Variables&#39;, title = &#39;Relative Variable Importance&#39;) + coord_flip() + theme_bw() AuthorXGB ## eXtreme Gradient Boosting ## ## 19579 samples ## 850 predictor ## 3 classes: &#39;EAP&#39;, &#39;HPL&#39;, &#39;MWS&#39; ## ## No pre-processing ## Resampling: None "],
["predictions-using-the-xgb-model.html", "Chapter 20 Predictions using the XGB Model", " Chapter 20 Predictions using the XGB Model predictions = predict(AuthorXGB,labeledTermsTest,type = &#39;prob&#39;) # Save the solution to a dataframe solution &lt;- data.frame(&#39;id&#39; = test$id, predictions) head(solution) ## id EAP HPL MWS ## 1 id02310 0.2020102 0.2493994 0.5485905 ## 2 id24541 0.4381515 0.3032378 0.2586108 ## 3 id00134 0.3396536 0.4587254 0.2016210 ## 4 id27757 0.4239962 0.3229545 0.2530494 ## 5 id04081 0.5903386 0.1773054 0.2323559 ## 6 id27337 0.3906093 0.3939233 0.2154674 # Write it to file write.csv(solution, &#39;XGBEDASpooky26Oct2017.csv&#39;, row.names = F) "],
["predictions-using-glmnet-model.html", "Chapter 21 Predictions using glmnet Model", " Chapter 21 Predictions using glmnet Model We predict using the glmnet model. AuthorGLM = train(formula, data = labeledTerms, method = &quot;glmnet&quot;,trControl = fitControl, na.action = na.pass,metric=&quot;LogLoss&quot;, maximize=FALSE) predictions = predict(AuthorGLM,labeledTermsTest,type = &#39;prob&#39;) # Save the solution to a dataframe solution &lt;- data.frame(&#39;id&#39; = test$id, predictions) head(solution) ## id EAP HPL MWS ## 1 id02310 0.1483739 0.05823763 0.793388478 ## 2 id24541 0.1367529 0.84022349 0.023023574 ## 3 id00134 0.4635034 0.53113156 0.005365013 ## 4 id27757 0.1716008 0.82497320 0.003425992 ## 5 id04081 0.7116491 0.10344372 0.184907176 ## 6 id27337 0.4591286 0.53811284 0.002758600 # Write it to file write.csv(solution, &#39;GLMNetEDASpooky29Oct2017.csv&#39;, row.names = F) "],
["modelling-using-the-text2vec-package.html", "Chapter 22 Modelling using the text2vec package 22.1 Inspect the vocabulary 22.2 Inspect the Document Term Matrix 22.3 Build the Multinomial Logistic Regression Model 22.4 Predict using the Multinomial Logistic Regression Model", " Chapter 22 Modelling using the text2vec package We create a vocabulary-based DTM. Here we collect unique terms from all documents and mark each of them with a unique ID using the create_vocabulary() function. We use an iterator to create the vocabulary. We also prune the vocabulary to reduce the terms in the matrix. prep_fun = function(x) { stringr::str_replace_all(tolower(x), &quot;[^[:alpha:]]&quot;, &quot; &quot;) } tok_fun = word_tokenizer it_train = itoken(train$text, preprocessor = prep_fun, tokenizer = tok_fun, ids = train$id, progressbar = FALSE) it_test = test$text %&gt;% prep_fun %&gt;% tok_fun %&gt;% itoken(ids = test$id, progressbar = FALSE) NFOLDS = 4 vocab = create_vocabulary(it_train, ngram = c(1L, 3L)) vocab = vocab %&gt;% prune_vocabulary(term_count_min = 10, doc_proportion_max = 0.5, doc_proportion_min = 0.01) trigram_vectorizer = vocab_vectorizer(vocab) dtm_train = create_dtm(it_train, trigram_vectorizer) dtm_test = create_dtm(it_test, trigram_vectorizer) 22.1 Inspect the vocabulary vocab ## Number of docs: 19579 ## 0 stopwords: ... ## ngram_min = 1; ngram_max = 3 ## Vocabulary: ## term term_count doc_count ## 1: black 198 196 ## 2: until 200 200 ## 3: over_the 201 198 ## 4: spirit 202 198 ## 5: open 203 199 ## --- ## 325: was 6647 5493 ## 326: in 9458 7101 ## 327: a 10750 7507 ## 328: i 10811 7075 ## 329: to 12843 8665 22.2 Inspect the Document Term Matrix dim(dtm_train) ## [1] 19579 329 22.3 Build the Multinomial Logistic Regression Model dtm_train &lt;- cBind(train$len, dtm_train) dtm_test &lt;- cBind(test$len, dtm_test) glmnet_classifier = cv.glmnet(x = dtm_train, y = train[[&#39;author&#39;]], family = &#39;multinomial&#39;, alpha = 1, type.measure = &quot;class&quot;, nfolds = NFOLDS, thresh = 1e-3, maxit = 1e3) 22.4 Predict using the Multinomial Logistic Regression Model preds = data.frame(id=test$id,predict(glmnet_classifier, dtm_test, type = &#39;response&#39;)) names(preds)[2] &lt;- &quot;EAP&quot; names(preds)[3] &lt;- &quot;HPL&quot; names(preds)[4] &lt;- &quot;MWS&quot; write_csv(preds, &quot;glmnet_benchmark_vocab_3N-grams.csv&quot;) "],
["introduction-1.html", "Chapter 23 Introduction", " Chapter 23 Introduction This dataset is a subset of Yelp’s businesses, reviews, and user data. It was originally put together for the Yelp Dataset Challenge which is a chance for students to conduct research or analysis on Yelp’s data and share their discoveries. In the dataset you will find information about businesses across 11 metropolitan areas in four countries.We will do a detailed EDA, Text Mining ,Network Analysis and Geospatial Analysis on this dataset.The dataset can be found in Kaggle For a city we spot the most popular business and also provide a map of the city of Las vegas with the business identified as dots in the map. We have analysed Las Vegas , Toronto and Phoenix.For Phoenix city, we also do Word Cloud, detailed Sentiment Analysis and Topic Modelling. For a business we do the following analysis Word Cloud of the reviews of the business Top Ten most common Words reviews of the business Sentiment Analysis - Postive and Not So Postive Words of reviews Calculate Sentiment for the reviews Negative Reviews Positive Reviews Most Common Bigrams (a collection of Two words) in the review text Relationship among words Relationship of words with an important word in the review such as steak, crab, food Topic Modelling of the reviews The business that we are analysing are Mon Ami Gabi , a Las Vegas Restaurant , the most popular and highly rated restaurants Bacchanal Buffet , the Second most popular and highly rated Las Vegas Restaurant Pai Northern Thai Kitchen , the most popular Toronto restaurant Chipotle Business in Yonge Street Toronto You guessed it right I like Chipotle :-) How Sentiment Analysis can help your business ? For a business, the Sentiment Analysis is very important. If the business owners can just see the Top Ten negative reviews, they can easily find out which aspect of the business they need to improve. For example, the Pai Northern Thai Kitchen, the complaints were about Service. Now when we go deeper into the Service complaints, we can find out various aspects of the service complaints such as why our waitress seemed to be in such a hurry to get us out of the place. This restaurant was crowded and noisy. The tables were packed so closely that I was falling over other diners while maneuvering to my seat but their service was God-awful. They rarely attended our table, It took 55 minutes for our food to arrive. They took our drink orders and did not deliver them Another interesting complaint for the Chipotle Business in Yonge Street Toronto was that they did not accept Interac , a standard payment method in Canada Examples involving it are as follows Not complying with customers' choice to pay with Interac, a standard payment method in Canada, is also a nuisance Only reason it got a 4 star is because they don't accept interac which is my go to. How Topic Modelling can help understand your business and city ? Topic modelling helps to pick specific topics from the huge volume of text. Topic Modelling on the Three popular restaurants and also on Phoenix City helps us to understand that complaints regarding restaurants and business is around Service "],
["preparation.html", "Chapter 24 Preparation 24.1 Load Libraries 24.2 Read the data", " Chapter 24 Preparation 24.1 Load Libraries library(tidyverse) # data manipulation and graphs library(stringr) # string manipulation library(lubridate) # date manipulation library(&#39;wordcloud&#39;) # wordcloud library(tidytext) # tidy implementation of NLP methods library(DT) # table format display of data library(leaflet) # maps library(igraph) # graphs library(ggraph) # graphs library(topicmodels) # for LDA topic modelling library(tm) # general text mining functions, making document term matrixes library(SnowballC) # for stemming library(textcat) 24.2 Read the data rm(list=ls()) fillColor = &quot;#FFA07A&quot; fillColor2 = &quot;#F1C40F&quot; reviews &lt;- read_csv(&#39;../input/yelp_review.csv&#39;) business &lt;- read_csv(&quot;../input/yelp_business.csv&quot;) "],
["business-data.html", "Chapter 25 Business data", " Chapter 25 Business data datatable(head(business), style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) "],
["reviews-data.html", "Chapter 26 Reviews data", " Chapter 26 Reviews data A glimpse of the reviews data glimpse(reviews) "],
["detecting-the-language-of-the-reviews.html", "Chapter 27 Detecting the language of the reviews", " Chapter 27 Detecting the language of the reviews Detecting the language of the first Ten reviews. textcat(reviews[1:10,]$text) "],
["most-popular-categories.html", "Chapter 28 Most Popular Categories", " Chapter 28 Most Popular Categories The most popular categories of business are plotted in the bar plot categories = str_split(business$categories,&quot;;&quot;) categories = as.data.frame(unlist(categories)) colnames(categories) = c(&quot;Name&quot;) categories %&gt;% group_by(Name) %&gt;% summarise(Count = n()) %&gt;% arrange(desc(Count)) %&gt;% ungroup() %&gt;% mutate(Name = reorder(Name,Count)) %&gt;% head(10) %&gt;% ggplot(aes(x = Name,y = Count)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor2) + geom_text(aes(x = Name, y = 1, label = paste0(&quot;(&quot;,Count,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Name of Category&#39;, y = &#39;Count&#39;, title = &#39;Top 10 Categories of Business&#39;) + coord_flip() + theme_bw() "],
["top-ten-cities-with-the-most-business-parties-mentioned-in-yelp.html", "Chapter 29 Top Ten Cities with the most Business parties mentioned in Yelp", " Chapter 29 Top Ten Cities with the most Business parties mentioned in Yelp We show the Top Ten Cities which has the most Business parties mentioned in Yelp business %&gt;% group_by(city) %&gt;% summarise(Count = n()) %&gt;% arrange(desc(Count)) %&gt;% ungroup() %&gt;% mutate(City = reorder(city,Count)) %&gt;% head(10) %&gt;% ggplot(aes(x = City,y = Count)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = City, y = 1, label = paste0(&quot;(&quot;,round(Count/1e3),&quot; K )&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;City&#39;, y = &#39;Count of Reviews&#39;, title = &#39;Top Ten Cities with the most Business parties in Yelp&#39;) + coord_flip() + theme_bw() "],
["map-of-the-business-parties-in-las-vegas.html", "Chapter 30 Map of the business parties in Las vegas", " Chapter 30 Map of the business parties in Las vegas Seems from the map that most of the business is in the neighborhood of The Strip in Las Vagas. From Wikipedia The Las Vegas Strip is a stretch of South Las Vegas Boulevard in Clark County, Nevada that is known for its concentration of resort hotels and casinos. The Strip is approximately 4.2 miles (6.8 km) in length,[1] located immediately south of the Las Vegas city limits in the unincorporated towns of Paradise and Winchester. LasvegasCoords = business %&gt;% filter(city == &quot;Las Vegas&quot;) center_lon = median(LasvegasCoords$longitude,na.rm = TRUE) center_lat = median(LasvegasCoords$latitude,na.rm = TRUE) leaflet(LasvegasCoords) %&gt;% addProviderTiles(&quot;Esri.NatGeoWorldMap&quot;) %&gt;% addCircles(lng = ~longitude, lat = ~latitude,radius = ~sqrt(review_count)) %&gt;% # controls setView(lng=center_lon, lat=center_lat,zoom = 13) "],
["business-with-most-five-star-reviews-from-users.html", "Chapter 31 Business with most Five Star Reviews from Users", " Chapter 31 Business with most Five Star Reviews from Users The following plot shows the names of business with the most Five Star Reviews.Mon Ami Gabi and Bacchanal Buffet are the Two most popular restaurants from the Yelp reviews with Five Star ratings. We will do a deep dive for these restaurants. most5StarsReviews = reviews %&gt;% filter(stars == 5) %&gt;% group_by(business_id) %&gt;% summarise(Count = n()) %&gt;% arrange(desc(Count)) %&gt;% ungroup() %&gt;% mutate(BusinessID = reorder(business_id,Count)) %&gt;% head(10) most5StarsReviews = inner_join(most5StarsReviews,business) most5StarsReviews %&gt;% mutate(name = reorder(name,Count)) %&gt;% ggplot(aes(x = name,y = Count)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor) + geom_text(aes(x = name, y = 1, label = paste0(&quot;(&quot;,Count,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Name of the Business&#39;, y = &#39;Count&#39;, title = &#39;Name of the Business and Count&#39;) + coord_flip() + theme_bw() "],
["mon-ami-gabi.html", "Chapter 32 “Mon Ami Gabi” 32.1 Useful,funny,cool reviews 32.2 Word Cloud of Mon Ami Gabi 32.3 Top Ten most common Words of the business “Mon Ami Gabi” 32.4 Sentiment Analysis - Postive and Not So Postive Words of “Mon Ami Gabi” 32.5 Calculate Sentiment for the reviews 32.6 Negative Reviews 32.7 Positive Reviews 32.8 Most Common Bigrams of “Mon Ami Gabi” 32.9 Relationship among words", " Chapter 32 “Mon Ami Gabi” The location and category of the most liked business Mon Ami Gabi is shown below mon_ami_gabi = business %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;) %&gt;% select(name,neighborhood,city,state,postal_code,categories) datatable(head(mon_ami_gabi), style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) 32.1 Useful,funny,cool reviews The following plot describes the number of Useful, Funny and Cool reviews.Most of the reviews are NOT useful , funny or cool. mon_ami_gabi_reviews = reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;) mon_ami_gabi_reviews %&gt;% group_by(useful) %&gt;% summarise(Count = n()) %&gt;% arrange(desc(Count)) %&gt;% ungroup() %&gt;% mutate(useful = reorder(useful,Count)) %&gt;% head(10) %&gt;% ggplot(aes(x = useful,y = Count)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor) + geom_text(aes(x = useful, y = 1, label = paste0(&quot;(&quot;,Count,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Useful Reviews&#39;, y = &#39;Count&#39;, title = &#39;Useful Reviews and Count&#39;) + coord_flip() + theme_bw() mon_ami_gabi_reviews %&gt;% group_by(funny) %&gt;% summarise(Count = n()) %&gt;% arrange(desc(Count)) %&gt;% ungroup() %&gt;% mutate(funny = reorder(funny,Count)) %&gt;% head(10) %&gt;% ggplot(aes(x = funny,y = Count)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor2) + geom_text(aes(x = funny, y = 1, label = paste0(&quot;(&quot;,Count,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Funny Reviews&#39;, y = &#39;Count&#39;, title = &#39;Funny Reviews and Count&#39;) + coord_flip() + theme_bw() mon_ami_gabi_reviews %&gt;% group_by(cool) %&gt;% summarise(Count = n()) %&gt;% arrange(desc(Count)) %&gt;% ungroup() %&gt;% mutate(cool = reorder(cool,Count)) %&gt;% head(10) %&gt;% ggplot(aes(x = cool,y = Count)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor) + geom_text(aes(x = cool, y = 1, label = paste0(&quot;(&quot;,Count,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Cool Reviews&#39;, y = &#39;Count&#39;, title = &#39;Cool Reviews and Count&#39;) + coord_flip() + theme_bw() 32.2 Word Cloud of Mon Ami Gabi A word cloud is a graphical representation of frequently used words in the text. The height of each word in this picture is an indication of frequency of occurrence of the word in the entire text. The words steak, service, vegas,french,patio,bellagio,delicious, nice are the words which have been used very frequently in the reviews.Note that if we choose a word which is not food related , it is Service and we will see in the subsequent sections of sentiment analysis and topic modelling , why this keyword is important. createWordCloud = function(train) { train %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% head(30) %&gt;% with(wordcloud(word, n, max.words = 30,colors=brewer.pal(8, &quot;Dark2&quot;))) } createWordCloud(reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;)) 32.3 Top Ten most common Words of the business “Mon Ami Gabi” We examine the Top Ten Most Common words and show them in a bar graph. The words steak, service, vegas,french,patio,bellagio,delicious, nice are the words which have been used very frequently in the reviews. reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;) %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% filter(!word %in% c(&#39;food&#39;,&#39;restaurant&#39;)) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% head(10) %&gt;% ggplot(aes(x = word,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = word, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Word&#39;, y = &#39;Word Count&#39;, title = &#39;Word Count&#39;) + coord_flip() + theme_bw() 32.4 Sentiment Analysis - Postive and Not So Postive Words of “Mon Ami Gabi” We display the Positive and Not So Positive words used by reviewers for the business Mon Ami Gabi.We have used the AFINN sentiment lexicon, which provides numeric positivity scores for each word, and visualize it with a bar plot. Breathtaking,funnier,fun,fantastic,fabulous,ecstatic,brilliant,awesome,amazing are some of the postive words that we have seen in the reviews of the business. positiveWordsBarGraph &lt;- function(SC) { contributions &lt;- SC %&gt;% unnest_tokens(word, text) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(word) %&gt;% summarize(occurences = n(), contribution = sum(score)) contributions %&gt;% top_n(20, abs(contribution)) %&gt;% mutate(word = reorder(word, contribution)) %&gt;% head(20) %&gt;% ggplot(aes(word, contribution, fill = contribution &gt; 0)) + geom_col(show.legend = FALSE) + coord_flip() + theme_bw() } positiveWordsBarGraph(reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;)) 32.5 Calculate Sentiment for the reviews We calculate the sentiment scores for all the reviews using the AFINN sentiment lexicon. We display the Top Six sentiments here. calculate_sentiment &lt;- function(review_text) { sentiment_lines = review_text %&gt;% filter(textcat(text) == &quot;english&quot;) %&gt;% # considering only English text unnest_tokens(word, text) %&gt;% inner_join(get_sentiments(&quot;afinn&quot;), by = &quot;word&quot;) %&gt;% group_by(review_id) %&gt;% summarize(sentiment = mean(score),words = n()) %&gt;% ungroup() %&gt;% filter(words &gt;= 5) return(sentiment_lines) } sentiment_lines = calculate_sentiment(mon_ami_gabi_reviews) head(sentiment_lines) 32.6 Negative Reviews We examine the Top Ten most negative reviews. The complaints were about Service. An excerpt of the Service Complaints is provided below Worst service ever. Didn't pay attention to our orders at all so we had to send most of the food back The server ignored us twice when we are talking to him. Threw the dishes instead of placing them on the table The service was mediocre and the food was terrible Food was OK, but service was terrible. Our server never came back to our table to check if we need another drink, water, bread, etc. We had to get somebody else's attention for our need. At the end, they included 18% tipping which is their policy for 5 or more people display_neg_sentiments &lt;- function(sentiment_lines,review_text) { neg_sentiment_lines = sentiment_lines %&gt;% arrange(desc(sentiment)) %&gt;% top_n(-10, sentiment) %&gt;% inner_join(review_text, by = &quot;review_id&quot;) %&gt;% select(date,sentiment,text) datatable(neg_sentiment_lines, style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) } display_neg_sentiments(sentiment_lines,mon_ami_gabi_reviews) 32.7 Positive Reviews We examine the Top Ten most positive reviews. display_pos_sentiments &lt;- function(sentiment_lines,review_text) { pos_sentiment_lines = sentiment_lines %&gt;% arrange(desc(sentiment)) %&gt;% top_n(10, sentiment) %&gt;% inner_join(review_text, by = &quot;review_id&quot;) %&gt;% select(date,sentiment,text) datatable(pos_sentiment_lines, style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) } display_pos_sentiments(sentiment_lines,mon_ami_gabi_reviews) 32.8 Most Common Bigrams of “Mon Ami Gabi” A Bigram is a collection of Two words. We examine the most common Bigrams and plot them in a bar plot. count_bigrams &lt;- function(dataset) { dataset %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;% separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) %&gt;% count(word1, word2, sort = TRUE) } visualize_bigrams &lt;- function(bigrams) { set.seed(2016) a &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;)) bigrams %&gt;% graph_from_data_frame() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a) + geom_node_point(color = &quot;lightblue&quot;, size = 5) + geom_node_text(aes(label = name), vjust = 1, hjust = 1) + theme_void() } visualize_bigrams_individual &lt;- function(bigrams) { set.seed(2016) a &lt;- grid::arrow(type = &quot;closed&quot;, length = unit(.15, &quot;inches&quot;)) bigrams %&gt;% graph_from_data_frame() %&gt;% ggraph(layout = &quot;fr&quot;) + geom_edge_link(aes(edge_alpha = n), show.legend = FALSE, arrow = a,end_cap = circle(.07, &#39;inches&#39;)) + geom_node_point(color = &quot;lightblue&quot;, size = 5) + geom_node_text(aes(label = name), vjust = 1, hjust = 1) + theme_void() } reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;) %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;% select(bigram,review_id) %&gt;% head(10) reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;) %&gt;% unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;% separate(bigram, c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;) %&gt;% filter(!word1 %in% stop_words$word, !word2 %in% stop_words$word) %&gt;% filter(!word1 %in% c(&quot;mon&quot;,&quot;ami&quot;)) %&gt;% filter(!word2 %in% c(&quot;gabi&quot;)) %&gt;% unite(bigramWord, word1, word2, sep = &quot; &quot;) %&gt;% group_by(bigramWord) %&gt;% tally() %&gt;% ungroup() %&gt;% arrange(desc(n)) %&gt;% mutate(bigramWord = reorder(bigramWord,n)) %&gt;% head(10) %&gt;% ggplot(aes(x = bigramWord,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill = fillColor2) + geom_text(aes(x = bigramWord, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Bigram&#39;, y = &#39;Count&#39;, title = &#39;Bigram and Count&#39;) + coord_flip() + theme_bw() 32.9 Relationship among words We explore the different relationship among the various words in Mon Ami Gabi reviews here through a network graph bigramsMonAmiGabi &lt;- reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;) %&gt;% count_bigrams() bigramsMonAmiGabi %&gt;% filter(n &gt; 50) %&gt;% visualize_bigrams() 32.9.1 Relationship of words with steak The following network diagram shows the words associated with the word steak bigramsMonAmiGabi %&gt;% filter(word1 == &quot;steak&quot; | word2 == &quot;steak&quot;) %&gt;% filter(n &gt; 30) %&gt;% visualize_bigrams() 32.9.2 Relationship of words with french The following network diagram shows the words associated with the word french bigramsMonAmiGabi %&gt;% filter(word1 == &quot;french&quot; | word2 == &quot;french&quot; ) %&gt;% filter(n &gt; 30) %&gt;% visualize_bigrams() "],
["bacchanal-buffet.html", "Chapter 33 Bacchanal Buffet 33.1 Word Cloud of Bacchanal Buffet 33.2 Top Ten most common Words of the business “Bacchanal Buffet” 33.3 Sentiment Analysis - Postive and Not So Postive Words of Bacchanal Buffet 33.4 Calculate Sentiment for the reviews 33.5 Negative Reviews 33.6 Positive Reviews 33.7 Relationship among words in Bacchanal Buffet", " Chapter 33 Bacchanal Buffet The location and category of the most liked business Bacchanal Buffet is shown below bacchanal = business %&gt;% filter(business_id == &quot;RESDUcs7fIiihp38-d6_6g&quot;) %&gt;% select(name,neighborhood,city,state,postal_code,categories) datatable(head(bacchanal), style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) 33.1 Word Cloud of Bacchanal Buffet bacchanal = reviews %&gt;% filter(business_id == &quot;RESDUcs7fIiihp38-d6_6g&quot;) createWordCloud(bacchanal) 33.2 Top Ten most common Words of the business “Bacchanal Buffet” We examine the Top Ten Most Common words and show them in a bar graph. bacchanal %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% filter(!word %in% c(&#39;food&#39;,&#39;restaurant&#39;)) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% head(10) %&gt;% ggplot(aes(x = word,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = word, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Word&#39;, y = &#39;Word Count&#39;, title = &#39;Word Count&#39;) + coord_flip() + theme_bw() 33.3 Sentiment Analysis - Postive and Not So Postive Words of Bacchanal Buffet We display the Positive and Not So Positive words used by reviewers for the business Bacchanal Buffet.We have used the AFINN sentiment lexicon, which provides numeric positivity scores for each word, and visualize it with a bar plot. positiveWordsBarGraph(bacchanal) 33.4 Calculate Sentiment for the reviews We calculate the sentiment scores for all the reviews using the AFINN sentiment lexicon. We display the Top Six sentiments here. sentiment_lines = calculate_sentiment(bacchanal) head(sentiment_lines) 33.5 Negative Reviews We examine the Top Ten most negative reviews.We examine the Top Ten most negative reviews. The complaints were about Service,waiting,decor. An excerpt of the Service Complaints is provided below this place sucks so fucking bad. We are waiting in line for almost one hour. They only let VIP members taking the available sits as soon as possible Stupid system!!!! Their ticketing idea sucks and defeats the purpose of having it at all!!! Service sucks! Server didn't even bother to check our table. I have to set a side my dirty plates on the other side of my table to be able have a space on our table display_neg_sentiments(sentiment_lines,bacchanal) 33.6 Positive Reviews We examine the Top Ten most postive reviews. display_pos_sentiments(sentiment_lines,bacchanal) 33.7 Relationship among words in Bacchanal Buffet We explore the different relationship among the various words in Bacchanal Buffet here through a network graph bigrams_bacchanal &lt;- bacchanal %&gt;% count_bigrams() bigrams_bacchanal %&gt;% filter(n &gt; 100) %&gt;% visualize_bigrams() 33.7.1 Relationship of words with crab The following network diagram shows the words associated with the word crab bigramsMonAmiGabi %&gt;% filter(word1 == &quot;crab&quot; | word2 == &quot;crab&quot; ) %&gt;% visualize_bigrams() 33.7.2 Relationship of words with food The following network diagram shows the words associated with the word food bigramsMonAmiGabi %&gt;% filter(word1 == &quot;food&quot; | word2 == &quot;food&quot; ) %&gt;% filter(n &gt; 10) %&gt;% visualize_bigrams() "],
["top-ten-business-in-toronto.html", "Chapter 34 Top Ten Business in Toronto", " Chapter 34 Top Ten Business in Toronto We list the Top Ten business in Toronto giving importance to the number of reviews and then to the number of stars obtained by the business. toronto_biz = business %&gt;% filter(city == &quot;Toronto&quot;) %&gt;% arrange(desc(review_count,stars)) %&gt;% select(name,neighborhood,address,review_count,stars) %&gt;% head(10) datatable(toronto_biz, style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) "],
["pai-northern-thai-kitchen.html", "Chapter 35 Pai Northern Thai Kitchen 35.1 Word Cloud of business Pai Northern Thai Kitchen 35.2 Ten most common words used in reviews of business Pai Northern Thai Kitchen 35.3 Sentiment Analysis - Postive and Not So Postive Words of Pai Northern Thai Kitchen 35.4 Calculate Sentiment for the reviews 35.5 Negative Reviews 35.6 Positive Reviews 35.7 Relationship among words in Pai Northern Thai Kitchen", " Chapter 35 Pai Northern Thai Kitchen 35.1 Word Cloud of business Pai Northern Thai Kitchen #r_BrIgzYcwo1NAuG9dLbpg createWordCloud(reviews %&gt;% filter(business_id == &quot;r_BrIgzYcwo1NAuG9dLbpg&quot;)) 35.2 Ten most common words used in reviews of business Pai Northern Thai Kitchen We examine the Top Ten Most Common words and show them in a bar graph. reviews %&gt;% filter(business_id == &quot;r_BrIgzYcwo1NAuG9dLbpg&quot;) %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% filter(!word %in% c(&#39;food&#39;,&#39;restaurant&#39;)) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% head(10) %&gt;% ggplot(aes(x = word,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = word, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Word&#39;, y = &#39;Word Count&#39;, title = &#39;Word Count&#39;) + coord_flip() + theme_bw() 35.3 Sentiment Analysis - Postive and Not So Postive Words of Pai Northern Thai Kitchen We display the Positive and Not So Positive words used by reviewers for the business Pai Northern Thai Kitchen.We have used the AFINN sentiment lexicon, which provides numeric positivity scores for each word, and visualize it with a bar plot. positiveWordsBarGraph(reviews %&gt;% filter(business_id == &quot;r_BrIgzYcwo1NAuG9dLbpg&quot;)) 35.4 Calculate Sentiment for the reviews We calculate the sentiment scores for all the reviews using the AFINN sentiment lexicon. We display the Top Six sentiments here. pai_thai = reviews %&gt;% filter(business_id == &quot;r_BrIgzYcwo1NAuG9dLbpg&quot;) sentiment_lines = calculate_sentiment(pai_thai) head(sentiment_lines) 35.5 Negative Reviews We examine the Top 10 most negative reviews.An analysis of the negative reviews reveals that the complaints were about Service. Now when we go deeper into the Service complaints, we can find out various aspects of the service complaints such as why our waitress seemed to be in such a hurry to get us out of the place. This restaurant was crowded and noisy. The tables were packed so closely that I was falling over other diners while maneuvering to my seat but their service was God-awful. They rarely attended our table, It took 55 minutes for our food to arrive. They took our drink orders and did not deliver them display_neg_sentiments(sentiment_lines,pai_thai) 35.6 Positive Reviews We examine the Top Ten most postive reviews. display_pos_sentiments(sentiment_lines,pai_thai) 35.7 Relationship among words in Pai Northern Thai Kitchen We explore the different relationship among the various words in *Pai Northern Thai Kitchen here through a network graph bigrams_thai &lt;- reviews %&gt;% filter(business_id == &quot;r_BrIgzYcwo1NAuG9dLbpg&quot;) %&gt;% count_bigrams() bigrams_thai %&gt;% filter(n &gt; 50) %&gt;% visualize_bigrams() 35.7.1 Relationship of words with thai The following network diagram shows the words associated with the word thai bigrams_thai %&gt;% filter(word1 == &quot;thai&quot; | word2 == &quot;thai&quot; ) %&gt;% filter(n &gt; 5) %&gt;% visualize_bigrams() "],
["chipotle-business.html", "Chapter 36 Chipotle business", " Chapter 36 Chipotle business We explore the various Chipotle business chipotle_biz = business %&gt;% filter(str_detect(name,&quot;Chipotle&quot;) )%&gt;% arrange(desc(review_count,stars)) datatable(head(chipotle_biz), style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) "],
["chipotle-business-in-yonge-street-toronto.html", "Chapter 37 Chipotle Business in Yonge Street Toronto 37.1 Word Cloud of business Chipotle Business in Yonge Street Toronto 37.2 Top Ten most common Words of the business “Chipotle Business in Yonge Street Toronto” 37.3 Sentiment Analysis - Postive and Not So Postive Words of Chipotle Business in Yonge Street Toronto 37.4 Calculate Sentiment for the reviews 37.5 Negative Reviews 37.6 Positive Reviews 37.7 Relationship among words in Chipotle Business in Yonge Street Toronto", " Chapter 37 Chipotle Business in Yonge Street Toronto We explore in detail the Chipotle business in Yonge Street Toronto since this has recived the highest number of reviews among the Chipotle business. 37.1 Word Cloud of business Chipotle Business in Yonge Street Toronto #gOBxVkHpqtjRRxHBIrpnMA chioptle_yonge = reviews %&gt;% filter(business_id == &quot;gOBxVkHpqtjRRxHBIrpnMA&quot;) createWordCloud(chioptle_yonge) 37.2 Top Ten most common Words of the business “Chipotle Business in Yonge Street Toronto” We examine the Top Ten Most Common words and show them in a bar graph. chioptle_yonge %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% filter(!word %in% c(&#39;food&#39;,&#39;restaurant&#39;)) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% head(10) %&gt;% ggplot(aes(x = word,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = word, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Word&#39;, y = &#39;Word Count&#39;, title = &#39;Word Count&#39;) + coord_flip() + theme_bw() 37.3 Sentiment Analysis - Postive and Not So Postive Words of Chipotle Business in Yonge Street Toronto We display the Positive and Not So Positive words used by reviewers for the business Chipotle Business in Yonge Street Toronto.We have used the AFINN sentiment lexicon, which provides numeric positivity scores for each word, and visualize it with a bar plot. positiveWordsBarGraph(chioptle_yonge) 37.4 Calculate Sentiment for the reviews We calculate the sentiment scores for all the reviews using the AFINN sentiment lexicon. We display the Top Six sentiments here. sentiment_lines = calculate_sentiment(chioptle_yonge) head(sentiment_lines) 37.5 Negative Reviews We examine the Top Ten most negative reviews.An interesting complaint for the Chipotle Business in Yonge Street Toronto was that they did not accept Interac , a standard payment method in Canada Examples involving it are as follows Not complying with customers' choice to pay with Interac, a standard payment method in Canada, is also a nuisance Only reason it got a 4 star is because they don't accept interac which is my go to. display_neg_sentiments(sentiment_lines,chioptle_yonge) 37.6 Positive Reviews We examine the Top Ten most postive reviews. display_pos_sentiments(sentiment_lines,chioptle_yonge) 37.7 Relationship among words in Chipotle Business in Yonge Street Toronto We explore the different relationship among the various words in Chipotle Business in Yonge Street Toronto here through a network graph bigrams_chioptle_yonge &lt;- chioptle_yonge %&gt;% count_bigrams() bigrams_chioptle_yonge %&gt;% filter(n &gt; 5) %&gt;% visualize_bigrams() "],
["topic-modelling.html", "Chapter 38 Topic Modelling 38.1 LDA Function 38.2 Topic Modelling for Mon Ami Gabi 38.3 Topic Modelling for Bacchanal Buffet 38.4 Topic Modelling for Pai Northern Thai Kitchen", " Chapter 38 Topic Modelling Topic modeling is a method for unsupervised classification of documents, similar to clustering on numeric data, which finds natural groups of items even when we’re not sure what we’re looking for. Latent Dirichlet allocation (LDA) is a particularly popular method for fitting a topic model. It treats each document as a mixture of topics, and each topic as a mixture of words. This allows documents to “overlap” each other in terms of content, rather than being separated into discrete groups, in a way that mirrors typical use of natural language. 38.1 LDA Function Borrowing an awesome function from Rachael’s Notebook # function to get &amp; plot the most informative terms by a specificed number # of topics, using LDA top_terms_by_topic_LDA &lt;- function(input_text, # should be a columm from a dataframe plot = T, # return a plot? TRUE by defult number_of_topics = 4) # number of topics (4 by default) { # create a corpus (type of object expected by tm) and document term matrix Corpus &lt;- Corpus(VectorSource(input_text)) # make a corpus object DTM &lt;- DocumentTermMatrix(Corpus) # get the count of words/document # remove any empty rows in our document term matrix (if there are any # we&#39;ll get an error when we try to run our LDA) unique_indexes &lt;- unique(DTM$i) # get the index of each unique value DTM &lt;- DTM[unique_indexes,] # get a subset of only those indexes # preform LDA &amp; get the words/topic in a tidy text format lda &lt;- LDA(DTM, k = number_of_topics, control = list(seed = 1234)) topics &lt;- tidy(lda, matrix = &quot;beta&quot;) # get the top ten terms for each topic top_terms &lt;- topics %&gt;% # take the topics data frame and.. group_by(topic) %&gt;% # treat each topic as a different group top_n(10, beta) %&gt;% # get the top 10 most informative words ungroup() %&gt;% # ungroup arrange(topic, -beta) # arrange words in descending informativeness # if the user asks for a plot (TRUE by default) if(plot == T){ # plot the top ten terms for each topic in order top_terms %&gt;% # take the top terms mutate(term = reorder(term, beta)) %&gt;% # sort terms by beta value ggplot(aes(term, beta, fill = factor(topic))) + # plot beta by theme geom_col(show.legend = FALSE) + # as a bar plot facet_wrap(~ topic, scales = &quot;free&quot;) + # which each topic in a seperate plot labs(x = NULL, y = &quot;Beta&quot;) + # no x label, change y label coord_flip() # turn bars sideways }else{ # if the user does not request a plot # return a list of sorted terms instead return(top_terms) } } 38.2 Topic Modelling for Mon Ami Gabi 4 topics for the Mon Ami Gabi create_LDA_topics &lt;- function(business_text,custom_stop_words) { # create a document term matrix to clean reviewsCorpus &lt;- Corpus(VectorSource(business_text$text)) reviewsDTM &lt;- DocumentTermMatrix(reviewsCorpus) # convert the document term matrix to a tidytext corpus reviewsDTM_tidy &lt;- tidy(reviewsDTM) # remove stopwords reviewsDTM_tidy_cleaned &lt;- reviewsDTM_tidy %&gt;% # take our tidy dtm and... anti_join(stop_words, by = c(&quot;term&quot; = &quot;word&quot;)) %&gt;% # remove English stopwords and... anti_join(custom_stop_words, by = c(&quot;term&quot; = &quot;word&quot;)) # remove my custom stopwords top_terms_by_topic_LDA(reviewsDTM_tidy_cleaned$term, number_of_topics = 4) } monamigabi = reviews %&gt;% filter(business_id == &quot;4JNXUYY8wbaaDmk3BPzlWw&quot;) custom_stop_words &lt;- tibble(word = c(&quot;mon&quot;,&quot;ami&quot;,&quot;gabi&quot;,&quot;restaurant&quot;,&quot;food&quot;,&quot;vegas&quot;)) create_LDA_topics(monamigabi,custom_stop_words) 38.3 Topic Modelling for Bacchanal Buffet 4 topics for the Bacchanal Buffet custom_stop_words &lt;- tibble(word = c(&quot;restaurant&quot;,&quot;food&quot;)) create_LDA_topics(bacchanal,custom_stop_words) 38.4 Topic Modelling for Pai Northern Thai Kitchen 4 topics for the Pai Northern Thai Kitchen custom_stop_words &lt;- tibble(word = c(&quot;thai&quot;,&quot;restaurant&quot;,&quot;food&quot;)) create_LDA_topics(pai_thai,custom_stop_words) We observe a common theme which appears across topics across the Three restaurants is service.The theme of service complaints was also very evident when we did the sentiment analysis "],
["phoenix-city-analysis.html", "Chapter 39 Phoenix City Analysis 39.1 Top Ten Business in Phoenix 39.2 Topic Modelling for Phoenix City 39.3 Word Cloud of Phoenix City 39.4 Top Ten most common Words of the business Phoenix City 39.5 Sentiment Analysis - Postive and Not So Postive Words of Phoenix City 39.6 Calculate Sentiment for the reviews 39.7 Negative Reviews 39.8 Positive Reviews", " Chapter 39 Phoenix City Analysis 39.1 Top Ten Business in Phoenix We list the Top Ten business in Toronto giving importance to the number of reviews and then to the number of stars obtained by the business. city_biz = business %&gt;% filter(city == &quot;Phoenix&quot;) %&gt;% arrange(desc(review_count,stars)) %&gt;% select(name,neighborhood,address,review_count,stars) %&gt;% head(10) datatable(city_biz, style=&quot;bootstrap&quot;, class=&quot;table-condensed&quot;, options = list(dom = &#39;tp&#39;,scrollX = TRUE)) 39.2 Topic Modelling for Phoenix City We do a Topic Modelling on the reviews of a sample of Ten Thousand Words of Phoenix City. CityCoords = business %&gt;% filter(city == &quot;Phoenix&quot;) city_words = inner_join(CityCoords,reviews) %&gt;% select(date,text,review_id) %&gt;% sample_n(10000) custom_stop_words &lt;- tibble(word = c(&quot;restaurant&quot;,&quot;food&quot;)) create_LDA_topics(city_words,custom_stop_words) We observe the themes of Service and time being very dominant. The occurence of the word chicken among food items is present. 39.3 Word Cloud of Phoenix City createWordCloud(city_words) 39.4 Top Ten most common Words of the business Phoenix City We examine the Top Ten Most Common words and show them in a bar graph. city_words %&gt;% unnest_tokens(word, text) %&gt;% filter(!word %in% stop_words$word) %&gt;% filter(!word %in% c(&#39;food&#39;,&#39;restaurant&#39;)) %&gt;% count(word,sort = TRUE) %&gt;% ungroup() %&gt;% mutate(word = factor(word, levels = rev(unique(word)))) %&gt;% head(10) %&gt;% ggplot(aes(x = word,y = n)) + geom_bar(stat=&#39;identity&#39;,colour=&quot;white&quot;, fill =fillColor) + geom_text(aes(x = word, y = 1, label = paste0(&quot;(&quot;,n,&quot;)&quot;,sep=&quot;&quot;)), hjust=0, vjust=.5, size = 4, colour = &#39;black&#39;, fontface = &#39;bold&#39;) + labs(x = &#39;Word&#39;, y = &#39;Word Count&#39;, title = &#39;Word Count&#39;) + coord_flip() + theme_bw() 39.5 Sentiment Analysis - Postive and Not So Postive Words of Phoenix City We display the Positive and Not So Positive words used by reviewers for Phoenix City.We have used the AFINN sentiment lexicon, which provides numeric positivity scores for each word, and visualize it with a bar plot. positiveWordsBarGraph(city_words) 39.6 Calculate Sentiment for the reviews We calculate the sentiment scores for all the reviews using the AFINN sentiment lexicon. We display the Top Six sentiments here. sentiment_lines = calculate_sentiment(city_words) head(sentiment_lines) 39.7 Negative Reviews We examine the Top Ten most negative reviews. display_neg_sentiments(sentiment_lines,city_words) 39.8 Positive Reviews We examine the Top Ten most postive reviews. display_pos_sentiments(sentiment_lines,city_words) "]
]
